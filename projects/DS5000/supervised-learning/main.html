<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Soong Ping Hill – Supervised Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Soong Ping Hill</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../../projects/DS5000/index.html">
 <span class="dropdown-text">Voting Behavior Prediction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projects/DS5100/index.html">
 <span class="dropdown-text">Airbnb Pricing Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projects/Scholarship/index.html">
 <span class="dropdown-text">Humanitarian Security Research</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../projects/DS5000/data-collection/main.html">Technical details</a></li><li class="breadcrumb-item"><a href="../../../projects/DS5000/supervised-learning/main.html">Supervised Learning</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/report.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Report</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Technical details</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/data-collection/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Collection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/data-cleaning/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Cleaning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/eda/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exploratory Data Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/unsupervised-learning/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unsupervised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/supervised-learning/main.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Supervised Learning</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#theory" id="toc-theory" class="nav-link" data-scroll-target="#theory">Theory</a></li>
  <li><a href="#regression" id="toc-regression" class="nav-link" data-scroll-target="#regression">Regression</a>
  <ul class="collapse">
  <li><a href="#regression-accuracy-metrics" id="toc-regression-accuracy-metrics" class="nav-link" data-scroll-target="#regression-accuracy-metrics">Regression Accuracy Metrics</a>
  <ul class="collapse">
  <li><a href="#mean-squared-error" id="toc-mean-squared-error" class="nav-link" data-scroll-target="#mean-squared-error">Mean Squared Error</a></li>
  <li><a href="#root-mean-squared-error" id="toc-root-mean-squared-error" class="nav-link" data-scroll-target="#root-mean-squared-error">Root Mean Squared Error</a></li>
  <li><a href="#mean-absolute-error" id="toc-mean-absolute-error" class="nav-link" data-scroll-target="#mean-absolute-error">Mean Absolute Error</a></li>
  <li><a href="#r2-value" id="toc-r2-value" class="nav-link" data-scroll-target="#r2-value">R^2 Value</a></li>
  <li><a href="#parity-plot" id="toc-parity-plot" class="nav-link" data-scroll-target="#parity-plot">Parity Plot</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#classification" id="toc-classification" class="nav-link" data-scroll-target="#classification">Classification</a>
  <ul class="collapse">
  <li><a href="#binary-classification" id="toc-binary-classification" class="nav-link" data-scroll-target="#binary-classification">Binary Classification</a></li>
  <li><a href="#multiclass-classification" id="toc-multiclass-classification" class="nav-link" data-scroll-target="#multiclass-classification">Multiclass Classification</a></li>
  <li><a href="#classification-accuracy-metrics" id="toc-classification-accuracy-metrics" class="nav-link" data-scroll-target="#classification-accuracy-metrics">Classification Accuracy Metrics</a>
  <ul class="collapse">
  <li><a href="#precision" id="toc-precision" class="nav-link" data-scroll-target="#precision">Precision</a></li>
  <li><a href="#recall" id="toc-recall" class="nav-link" data-scroll-target="#recall">Recall</a></li>
  <li><a href="#false-positive-rate" id="toc-false-positive-rate" class="nav-link" data-scroll-target="#false-positive-rate">False Positive Rate</a></li>
  <li><a href="#f1-score" id="toc-f1-score" class="nav-link" data-scroll-target="#f1-score">F1 Score</a></li>
  <li><a href="#roc-curve" id="toc-roc-curve" class="nav-link" data-scroll-target="#roc-curve">ROC Curve</a></li>
  <li><a href="#auc-score" id="toc-auc-score" class="nav-link" data-scroll-target="#auc-score">AUC Score</a></li>
  <li><a href="#accuracy" id="toc-accuracy" class="nav-link" data-scroll-target="#accuracy">Accuracy</a></li>
  <li><a href="#macro-average" id="toc-macro-average" class="nav-link" data-scroll-target="#macro-average">Macro Average</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#supervised-learning-methods" id="toc-supervised-learning-methods" class="nav-link" data-scroll-target="#supervised-learning-methods">Supervised Learning Methods</a>
  <ul class="collapse">
  <li><a href="#regression-1" id="toc-regression-1" class="nav-link" data-scroll-target="#regression-1">Regression</a>
  <ul class="collapse">
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression">Linear Regression</a></li>
  <li><a href="#lasso-regression" id="toc-lasso-regression" class="nav-link" data-scroll-target="#lasso-regression">Lasso Regression</a></li>
  </ul></li>
  <li><a href="#classification-1" id="toc-classification-1" class="nav-link" data-scroll-target="#classification-1">Classification</a>
  <ul class="collapse">
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression">Logistic Regression</a></li>
  </ul></li>
  <li><a href="#decision-tree" id="toc-decision-tree" class="nav-link" data-scroll-target="#decision-tree">Decision Tree</a>
  <ul class="collapse">
  <li><a href="#parameters" id="toc-parameters" class="nav-link" data-scroll-target="#parameters">Parameters</a></li>
  </ul></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest">Random Forest</a>
  <ul class="collapse">
  <li><a href="#how-it-works" id="toc-how-it-works" class="nav-link" data-scroll-target="#how-it-works">How It Works:</a></li>
  <li><a href="#parameters-1" id="toc-parameters-1" class="nav-link" data-scroll-target="#parameters-1">Parameters</a></li>
  </ul></li>
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation">Cross Validation</a>
  <ul class="collapse">
  <li><a href="#why-cross-validation-is-important" id="toc-why-cross-validation-is-important" class="nav-link" data-scroll-target="#why-cross-validation-is-important">Why Cross Validation is Important</a></li>
  <li><a href="#advantages" id="toc-advantages" class="nav-link" data-scroll-target="#advantages">Advantages</a></li>
  <li><a href="#disadvantages" id="toc-disadvantages" class="nav-link" data-scroll-target="#disadvantages">Disadvantages</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#feature-selection" id="toc-feature-selection" class="nav-link" data-scroll-target="#feature-selection">Feature Selection</a>
  <ul class="collapse">
  <li><a href="#one-hot-encoding" id="toc-one-hot-encoding" class="nav-link" data-scroll-target="#one-hot-encoding">One Hot Encoding</a>
  <ul class="collapse">
  <li><a href="#what-is-one-hot-encoding" id="toc-what-is-one-hot-encoding" class="nav-link" data-scroll-target="#what-is-one-hot-encoding">What is One Hot Encoding?</a></li>
  <li><a href="#final-features" id="toc-final-features" class="nav-link" data-scroll-target="#final-features">Final Features:</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#regression-2" id="toc-regression-2" class="nav-link" data-scroll-target="#regression-2">Regression</a>
  <ul class="collapse">
  <li><a href="#linear-regression-feature-importance" id="toc-linear-regression-feature-importance" class="nav-link" data-scroll-target="#linear-regression-feature-importance">Linear Regression Feature Importance</a></li>
  <li><a href="#linear-regression-accuracy-analysis" id="toc-linear-regression-accuracy-analysis" class="nav-link" data-scroll-target="#linear-regression-accuracy-analysis">Linear Regression Accuracy Analysis</a></li>
  <li><a href="#cross-validation-1" id="toc-cross-validation-1" class="nav-link" data-scroll-target="#cross-validation-1">Cross Validation</a></li>
  <li><a href="#cross-validation-linear-regression-accuracy-analysis" id="toc-cross-validation-linear-regression-accuracy-analysis" class="nav-link" data-scroll-target="#cross-validation-linear-regression-accuracy-analysis">Cross Validation Linear Regression Accuracy Analysis</a></li>
  <li><a href="#lasso-regression-1" id="toc-lasso-regression-1" class="nav-link" data-scroll-target="#lasso-regression-1">Lasso Regression</a></li>
  <li><a href="#lasso-regression-accuracy-analysis" id="toc-lasso-regression-accuracy-analysis" class="nav-link" data-scroll-target="#lasso-regression-accuracy-analysis">Lasso Regression Accuracy Analysis</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#real-world-application" id="toc-real-world-application" class="nav-link" data-scroll-target="#real-world-application">Real World Application</a></li>
  </ul></li>
  <li><a href="#binary-classification-1" id="toc-binary-classification-1" class="nav-link" data-scroll-target="#binary-classification-1">Binary Classification</a>
  <ul class="collapse">
  <li><a href="#target-selection" id="toc-target-selection" class="nav-link" data-scroll-target="#target-selection">Target Selection</a></li>
  <li><a href="#log-regression-binary-classification" id="toc-log-regression-binary-classification" class="nav-link" data-scroll-target="#log-regression-binary-classification">Log Regression Binary Classification</a></li>
  <li><a href="#log-binary-classification-accuracy-analysis" id="toc-log-binary-classification-accuracy-analysis" class="nav-link" data-scroll-target="#log-binary-classification-accuracy-analysis">Log Binary Classification Accuracy Analysis</a>
  <ul class="collapse">
  <li><a href="#precision-1" id="toc-precision-1" class="nav-link" data-scroll-target="#precision-1">Precision</a></li>
  <li><a href="#recall-1" id="toc-recall-1" class="nav-link" data-scroll-target="#recall-1">Recall</a></li>
  <li><a href="#f1" id="toc-f1" class="nav-link" data-scroll-target="#f1">F1</a></li>
  <li><a href="#confusion-matrix" id="toc-confusion-matrix" class="nav-link" data-scroll-target="#confusion-matrix">Confusion Matrix</a></li>
  <li><a href="#roc-curve-1" id="toc-roc-curve-1" class="nav-link" data-scroll-target="#roc-curve-1">ROC Curve</a></li>
  </ul></li>
  <li><a href="#decision-tree-binary-classification" id="toc-decision-tree-binary-classification" class="nav-link" data-scroll-target="#decision-tree-binary-classification">Decision Tree Binary Classification</a></li>
  <li><a href="#decision-tree-binary-classification-accuracy-analysis" id="toc-decision-tree-binary-classification-accuracy-analysis" class="nav-link" data-scroll-target="#decision-tree-binary-classification-accuracy-analysis">Decision Tree Binary Classification Accuracy Analysis</a>
  <ul class="collapse">
  <li><a href="#precision-2" id="toc-precision-2" class="nav-link" data-scroll-target="#precision-2">Precision</a></li>
  <li><a href="#recall-2" id="toc-recall-2" class="nav-link" data-scroll-target="#recall-2">Recall</a></li>
  <li><a href="#f1-1" id="toc-f1-1" class="nav-link" data-scroll-target="#f1-1">F1</a></li>
  <li><a href="#confusion-matrix-1" id="toc-confusion-matrix-1" class="nav-link" data-scroll-target="#confusion-matrix-1">Confusion Matrix</a></li>
  <li><a href="#decision-tree-1" id="toc-decision-tree-1" class="nav-link" data-scroll-target="#decision-tree-1">Decision Tree</a></li>
  </ul></li>
  <li><a href="#random-forest-binary-classification" id="toc-random-forest-binary-classification" class="nav-link" data-scroll-target="#random-forest-binary-classification">Random Forest Binary Classification</a></li>
  <li><a href="#random-forest-binary-classification-feature-importance" id="toc-random-forest-binary-classification-feature-importance" class="nav-link" data-scroll-target="#random-forest-binary-classification-feature-importance">Random Forest Binary Classification Feature Importance</a></li>
  <li><a href="#random-forest-binary-classification-accuracy-analysis" id="toc-random-forest-binary-classification-accuracy-analysis" class="nav-link" data-scroll-target="#random-forest-binary-classification-accuracy-analysis">Random Forest Binary Classification Accuracy Analysis</a>
  <ul class="collapse">
  <li><a href="#precision-3" id="toc-precision-3" class="nav-link" data-scroll-target="#precision-3">Precision</a></li>
  <li><a href="#recall-3" id="toc-recall-3" class="nav-link" data-scroll-target="#recall-3">Recall</a></li>
  <li><a href="#f1-2" id="toc-f1-2" class="nav-link" data-scroll-target="#f1-2">F1</a></li>
  <li><a href="#confusion-matrix-2" id="toc-confusion-matrix-2" class="nav-link" data-scroll-target="#confusion-matrix-2">Confusion Matrix</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#binary-method-analysis-and-comparison" id="toc-binary-method-analysis-and-comparison" class="nav-link" data-scroll-target="#binary-method-analysis-and-comparison">Binary Method Analysis and Comparison</a>
  <ul class="collapse">
  <li><a href="#logistic-regression---lower-voting-class" id="toc-logistic-regression---lower-voting-class" class="nav-link" data-scroll-target="#logistic-regression---lower-voting-class">Logistic Regression - Lower Voting Class</a></li>
  <li><a href="#random-forest---lower-voting-class" id="toc-random-forest---lower-voting-class" class="nav-link" data-scroll-target="#random-forest---lower-voting-class">Random Forest - Lower Voting Class</a></li>
  <li><a href="#logistic-regression---higher-voting-class" id="toc-logistic-regression---higher-voting-class" class="nav-link" data-scroll-target="#logistic-regression---higher-voting-class">Logistic Regression - Higher Voting Class</a></li>
  <li><a href="#random-forest---higher-voting-class" id="toc-random-forest---higher-voting-class" class="nav-link" data-scroll-target="#random-forest---higher-voting-class">Random Forest - Higher Voting Class</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul></li>
  <li><a href="#multiclass-classification-1" id="toc-multiclass-classification-1" class="nav-link" data-scroll-target="#multiclass-classification-1">Multiclass Classification</a>
  <ul class="collapse">
  <li><a href="#target-selection-1" id="toc-target-selection-1" class="nav-link" data-scroll-target="#target-selection-1">Target Selection</a></li>
  <li><a href="#log-regression-multiclass-classification" id="toc-log-regression-multiclass-classification" class="nav-link" data-scroll-target="#log-regression-multiclass-classification">Log Regression Multiclass Classification</a></li>
  <li><a href="#log-regression-multiclass-classification-analysis" id="toc-log-regression-multiclass-classification-analysis" class="nav-link" data-scroll-target="#log-regression-multiclass-classification-analysis">Log Regression Multiclass Classification Analysis</a>
  <ul class="collapse">
  <li><a href="#high-voting-rates" id="toc-high-voting-rates" class="nav-link" data-scroll-target="#high-voting-rates">High Voting Rates</a></li>
  <li><a href="#low-voting-rates" id="toc-low-voting-rates" class="nav-link" data-scroll-target="#low-voting-rates">Low Voting Rates</a></li>
  <li><a href="#median-voting-rates" id="toc-median-voting-rates" class="nav-link" data-scroll-target="#median-voting-rates">Median Voting Rates</a></li>
  <li><a href="#macro-average-1" id="toc-macro-average-1" class="nav-link" data-scroll-target="#macro-average-1">Macro Average</a></li>
  <li><a href="#confusion-matrix-3" id="toc-confusion-matrix-3" class="nav-link" data-scroll-target="#confusion-matrix-3">Confusion Matrix</a></li>
  <li><a href="#roc-curve-2" id="toc-roc-curve-2" class="nav-link" data-scroll-target="#roc-curve-2">ROC Curve</a></li>
  </ul></li>
  <li><a href="#decision-tree-multiclass-classification" id="toc-decision-tree-multiclass-classification" class="nav-link" data-scroll-target="#decision-tree-multiclass-classification">Decision Tree Multiclass Classification</a></li>
  <li><a href="#decision-tree-multiclass-classification-analysis" id="toc-decision-tree-multiclass-classification-analysis" class="nav-link" data-scroll-target="#decision-tree-multiclass-classification-analysis">Decision Tree Multiclass Classification Analysis</a>
  <ul class="collapse">
  <li><a href="#high-voting-rates-1" id="toc-high-voting-rates-1" class="nav-link" data-scroll-target="#high-voting-rates-1">High Voting Rates</a></li>
  <li><a href="#low-voting-rates-1" id="toc-low-voting-rates-1" class="nav-link" data-scroll-target="#low-voting-rates-1">Low Voting Rates</a></li>
  <li><a href="#median-voting-rates-1" id="toc-median-voting-rates-1" class="nav-link" data-scroll-target="#median-voting-rates-1">Median Voting Rates</a></li>
  <li><a href="#accuracy-1" id="toc-accuracy-1" class="nav-link" data-scroll-target="#accuracy-1">Accuracy</a></li>
  <li><a href="#macro-average-2" id="toc-macro-average-2" class="nav-link" data-scroll-target="#macro-average-2">Macro Average</a></li>
  <li><a href="#confusion-matrix-4" id="toc-confusion-matrix-4" class="nav-link" data-scroll-target="#confusion-matrix-4">Confusion Matrix</a></li>
  </ul></li>
  <li><a href="#decision-tree-2" id="toc-decision-tree-2" class="nav-link" data-scroll-target="#decision-tree-2">Decision Tree</a></li>
  <li><a href="#random-forest-multiclass-classification" id="toc-random-forest-multiclass-classification" class="nav-link" data-scroll-target="#random-forest-multiclass-classification">Random Forest Multiclass Classification</a></li>
  <li><a href="#random-forest-multiclass-classification-feature-importance" id="toc-random-forest-multiclass-classification-feature-importance" class="nav-link" data-scroll-target="#random-forest-multiclass-classification-feature-importance">Random Forest Multiclass Classification Feature Importance</a></li>
  <li><a href="#random-forest-multiclass-classification-analysis" id="toc-random-forest-multiclass-classification-analysis" class="nav-link" data-scroll-target="#random-forest-multiclass-classification-analysis">Random Forest Multiclass Classification Analysis</a>
  <ul class="collapse">
  <li><a href="#high-voting-rates-2" id="toc-high-voting-rates-2" class="nav-link" data-scroll-target="#high-voting-rates-2">High Voting Rates</a></li>
  <li><a href="#low-voting-rates-2" id="toc-low-voting-rates-2" class="nav-link" data-scroll-target="#low-voting-rates-2">Low Voting Rates</a></li>
  <li><a href="#median-voting-rates-2" id="toc-median-voting-rates-2" class="nav-link" data-scroll-target="#median-voting-rates-2">Median Voting Rates</a></li>
  <li><a href="#accuracy-2" id="toc-accuracy-2" class="nav-link" data-scroll-target="#accuracy-2">Accuracy</a></li>
  <li><a href="#macro-average-3" id="toc-macro-average-3" class="nav-link" data-scroll-target="#macro-average-3">Macro Average</a></li>
  <li><a href="#confusion-matrix-5" id="toc-confusion-matrix-5" class="nav-link" data-scroll-target="#confusion-matrix-5">Confusion Matrix</a></li>
  </ul></li>
  <li><a href="#multiclass-classification-analysis-and-comparison" id="toc-multiclass-classification-analysis-and-comparison" class="nav-link" data-scroll-target="#multiclass-classification-analysis-and-comparison">Multiclass Classification Analysis and Comparison</a></li>
  </ul></li>
  <li><a href="#conclusion-1" id="toc-conclusion-1" class="nav-link" data-scroll-target="#conclusion-1">Conclusion</a>
  <ul class="collapse">
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link" data-scroll-target="#supervised-learning">Supervised Learning</a>
  <ul class="collapse">
  <li><a href="#regression-3" id="toc-regression-3" class="nav-link" data-scroll-target="#regression-3">Regression</a></li>
  <li><a href="#binary-classification-2" id="toc-binary-classification-2" class="nav-link" data-scroll-target="#binary-classification-2">Binary Classification</a></li>
  <li><a href="#multiclass-classification-2" id="toc-multiclass-classification-2" class="nav-link" data-scroll-target="#multiclass-classification-2">Multiclass Classification</a></li>
  </ul></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next Steps</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../projects/DS5000/data-collection/main.html">Technical details</a></li><li class="breadcrumb-item"><a href="../../../projects/DS5000/supervised-learning/main.html">Supervised Learning</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Supervised Learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- After digesting the instructions, you can delete this cell, these are assignment instructions and do not need to be included in your final submission.  -->
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Supervised Learning is a type of Machine Learning where the model is trained with labeled data, and learns relationships between the input and target variable. Once the model learns the relationships, begins to predict or categorize unseen data.</p>
<ul>
<li>The two main types of Supervised learning include
<ul>
<li>Regression</li>
<li>Classification</li>
</ul></li>
</ul>
<p>Utilizing Supervised Learning for predicting voting rates is important because it allows us to understand the relationship of input features and voting rate. Furthermore, we have a clear objective, with predicting voting rate as the continuous variable for regression and classifying districts between high and low voting rate</p>
<hr>
</section>
<section id="theory" class="level1">
<h1>Theory</h1>
<hr>
</section>
<section id="regression" class="level1">
<h1>Regression</h1>
<ul>
<li><p>Regression is a type of supervised learning that is given labeled data, and the goal is to predict a continuous target variable. It does this by learning the mathematical relationships between the input data and target variable. The data is first cleaned, and the appropriate features are chosen. The data is then split into <strong>training</strong> and <strong>test</strong> sets.</p></li>
<li><p>The purpose of splitting data into train and test sets is to:</p>
<ul>
<li><strong>Limit overfitting</strong>: Prevent the model from performing very well on data it has seen but poorly on new, unseen data.<br>
</li>
<li>By utilizing the test set, you can evaluate how accurate the model is with predicting unseen data.</li>
</ul></li>
</ul>
<hr>
<section id="regression-accuracy-metrics" class="level2">
<h2 class="anchored" data-anchor-id="regression-accuracy-metrics">Regression Accuracy Metrics</h2>
<p>The accuracy of a regression model is explained by a series of metrics, MSE, RMSE (Root Mean Square Error), R^2, MAE (Mean Absolute Error), and a parity plot.</p>
<section id="mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="mean-squared-error">Mean Squared Error</h3>
<ul>
<li>MSE quantifies the average squared difference between the actual y values and predicted y values.</li>
<li>Squaring the difference causes the larger errors to be heavily penalized.</li>
<li>This is utilized as a metric to evaluate model performance, with smaller values indicating a more accurate prediction.</li>
</ul>
<p><span class="math display">\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]</span></p>
<hr>
</section>
<section id="root-mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="root-mean-squared-error">Root Mean Squared Error</h3>
<ul>
<li>RMSE represents the square root of Mean Squared Error (MSE).<br>
</li>
<li>As stated earlier, MSE computes the squared difference between predicted and actual values</li>
<li>Taking the square root of MSE places the metric in the same units as the target values, making it more easy to understand and interpret.</li>
<li>A smaller RMSE value indicates a smaller difference between predicted and actual values, and a more accurate model</li>
<li>We will be using RMSE instead of MSE to test accuracy due to its increased interpretability.</li>
</ul>
<p><span class="math display">\[
\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
\]</span></p>
<hr>
</section>
<section id="mean-absolute-error" class="level3">
<h3 class="anchored" data-anchor-id="mean-absolute-error">Mean Absolute Error</h3>
<ul>
<li>MAE also measures the difference between actual and predicted values.<br>
</li>
<li>However, it only measures the average absolute difference between actual and predicted values.<br>
</li>
<li>Unlike MSE and RMSE, it does not penalize larger error.</li>
</ul>
<p><span class="math display">\[
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
\]</span></p>
<hr>
</section>
<section id="r2-value" class="level3">
<h3 class="anchored" data-anchor-id="r2-value">R^2 Value</h3>
<ul>
<li>R-squared computes the proportion of variance in the target variable explained by the features in the data.<br>
</li>
<li>The residual sum of squares (the sum of differences between actual values and predicted values) is divided by Total sum of Squares (sum of differences between the actual value and the mean of all values).<br>
</li>
<li>The Residual Sum of Squares quantifies the sum of differences between actual and predicted values, while the Total Sum of Squares computes the sum of squared deviations between actual values and the mean.</li>
</ul>
<p><span class="math display">\[
\text{RSS} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]</span></p>
<p><span class="math display">\[
\text{TSS} = \sum_{i=1}^{n} (y_i - \bar{y})^2
\]</span></p>
<ul>
<li>Subtracting this proportion by 1 provides us the proportion of variance that the model explains.<br>
</li>
<li>This value ranges from 0 to 1, a higher value indicating a greater portion of the variance is explained by the features.</li>
</ul>
<p><span class="math display">\[
R^2 = 1 - \frac{\text{RSS}}{\text{TSS}}
\]</span></p>
<hr>
</section>
<section id="parity-plot" class="level3">
<h3 class="anchored" data-anchor-id="parity-plot">Parity Plot</h3>
<ul>
<li>A Parity Plot is a visual representation that shows the distribution of actual and predicted values.<br>
</li>
<li>A line is plotted showcasing what a perfect fit would look like, and both actual and predicted values are plotted.<br>
</li>
<li>If data points are close to the line of best fit, this represents the model is accurate, and if they are far away it indicates the model has errors.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="classification" class="level1">
<h1>Classification</h1>
<p>Classification is form of supervised learning where data is trained on data with labels, and tasked with classifying an instance into different categories. There are many types of classification methods, including Binary and Multiclass Classification.</p>
<hr>
<section id="binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="binary-classification">Binary Classification</h2>
<ul>
<li>Binary Classification is a form of classification where the model must classify data into two groups.<br>
</li>
<li>A binary target is chosen for the model to classify the data into, and similar to regression, the data is split into train and test split, but this time to learn the relationship between the binary target and features.<br>
</li>
<li><strong>Examples</strong>:
<ul>
<li>Classifying data into <strong>High and Low</strong><br>
</li>
<li>Classifying data into <strong>Boy and Girl</strong><br>
</li>
<li>Classifying data into <strong>Cat and Dog</strong></li>
</ul></li>
</ul>
<hr>
</section>
<section id="multiclass-classification" class="level2">
<h2 class="anchored" data-anchor-id="multiclass-classification">Multiclass Classification</h2>
<ul>
<li>Multiclass classification is a form of Supervised learning where there are many categories, and the model attempts to classify an instance into a category.<br>
</li>
<li><strong>Examples</strong>:
<ul>
<li>Classifying an image into categories of <strong>Dog</strong>, <strong>Cat</strong> or <strong>House</strong>.<br>
</li>
<li>Classifying data as <strong>Low,</strong> <strong>Medium</strong> or <strong>High</strong></li>
</ul></li>
<li>There are multiple forms of classification models, including:
<ul>
<li><strong>Linear models</strong>: Logistic Regression<br>
</li>
<li><strong>Tree-Based models</strong>: Decision Trees, Random Forests, and Gradient Boost.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="classification-accuracy-metrics" class="level2">
<h2 class="anchored" data-anchor-id="classification-accuracy-metrics">Classification Accuracy Metrics</h2>
<section id="precision" class="level3">
<h3 class="anchored" data-anchor-id="precision">Precision</h3>
<ul>
<li>Precision measures the proportion of positive instances that are labeled positive.<br>
</li>
<li>It is used to check for <strong>False Positives</strong>, where values were incorrectly labeled as True when they were actually False.<br>
</li>
<li>A higher precision score indicates fewer False Positives identified.</li>
</ul>
<p><span class="math display">\[
\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}
\]</span></p>
<hr>
</section>
<section id="recall" class="level3">
<h3 class="anchored" data-anchor-id="recall">Recall</h3>
<ul>
<li>Recall, also known as <strong>Sensitivity</strong>, measures the proportion of actual positives the model correctly identifies.<br>
</li>
<li>Recall is used to check for <strong>False Negatives</strong>, where values were incorrectly labeled as False when they were actually positive.<br>
</li>
<li>A higher Recall score indicates fewer False Negatives identified.</li>
</ul>
<p><span class="math display">\[
\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
\]</span></p>
<hr>
</section>
<section id="false-positive-rate" class="level3">
<h3 class="anchored" data-anchor-id="false-positive-rate">False Positive Rate</h3>
<ul>
<li>The False Positive Rate, or <strong>Specificity</strong>, indicates the proportion of instances labeled False Positives compared to those that are actually Negative.<br>
</li>
<li>False positives are instances that are negative but predicted as positive.</li>
</ul>
<p><span class="math display">\[
\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}
\]</span></p>
<hr>
</section>
<section id="f1-score" class="level3">
<h3 class="anchored" data-anchor-id="f1-score">F1 Score</h3>
<ul>
<li>F1 Score combines the <strong>Precision</strong> and <strong>Recall</strong> score, utilizing both metrics to evaluate the accuracy of the model.<br>
</li>
<li>It provides a single score that balances the tradeoffs between the two metrics.<br>
</li>
<li>A higher F1 score indicates both Precision and Recall are high and accurate.</li>
</ul>
<p><span class="math display">\[
\text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\]</span></p>
<hr>
</section>
<section id="roc-curve" class="level3">
<h3 class="anchored" data-anchor-id="roc-curve">ROC Curve</h3>
<ul>
<li><p>An <strong>Receiver Operating Characteristic (ROC) Curve</strong> visualizes the accuracy of the model, plotting the <strong>True Positive Rate</strong> (Recall) against the <strong>False Positive Rate</strong>.<br>
</p></li>
<li><p>By plotting these two values against each other, we can visualize the tradeoff between Recall (accuracy of true positives) and Specificity (accuracy of false positives).<br>
</p></li>
<li><p>The diagram showcases a diagonal (baseline), from (0,0) to (1, 1) representing a completely random classifier.</p></li>
<li><p>If the model’s ROC is <strong>higher than this baseline</strong>, it means the model performs better than random guessing.<br>
</p></li>
<li><p>If <strong>below the line</strong>, it means the model performs worse.</p></li>
</ul>
<hr>
</section>
<section id="auc-score" class="level3">
<h3 class="anchored" data-anchor-id="auc-score">AUC Score</h3>
<ul>
<li>The <strong>Area Under the Curve (AUC)</strong> score quantifies the total area under the ROC curve.<br>
</li>
<li>This measures the overall performance of the model:
<ul>
<li><strong>1</strong>: Perfect model<br>
</li>
<li><strong>0.5</strong>: Random guessing<br>
</li>
<li><strong>&lt; 0.5</strong>: Worse than random guessing.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="accuracy" class="level3">
<h3 class="anchored" data-anchor-id="accuracy">Accuracy</h3>
<ul>
<li>The <strong>Accuracy</strong> is the ratio of correctly predicted instances to total instances.<br>
</li>
<li>It measures the total true accuracy of the model, with a higher value indicating our model classified predictions correctly.</li>
<li><span class="math display">\[
\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{Total Observations}}
\]</span></li>
</ul>
<hr>
</section>
<section id="macro-average" class="level3">
<h3 class="anchored" data-anchor-id="macro-average">Macro Average</h3>
<ul>
<li>A <strong>Macro Average</strong> measures the combined accuracy metric performance of all classes.<br>
</li>
<li>It computes the unweighted mean of precision, recall, and F1 scores across all classes.</li>
</ul>
<p><span class="math display">\[
\text{Macro Average} = \frac{1}{N} \sum_{i=1}^N \text{Metric}_i
\]</span></p>
</section>
</section>
</section>
<section id="supervised-learning-methods" class="level1">
<h1>Supervised Learning Methods</h1>
<p>There are many types of supervised learning methods, including:</p>
<ul>
<li><strong>Logistic Regression</strong><br>
</li>
<li><strong>Decision Tree</strong><br>
</li>
<li><strong>Random Forest</strong></li>
</ul>
<hr>
<section id="regression-1" class="level2">
<h2 class="anchored" data-anchor-id="regression-1">Regression</h2>
<section id="linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression">Linear Regression</h3>
<ul>
<li><strong>Linear Regression</strong> predicts a continuous target variable by modeling a linear relationship between input features and the target.</li>
<li>The model:
<ul>
<li>Takes in features.<br>
</li>
<li>Combines features and weight</li>
</ul></li>
</ul>
<p><span class="math display">\[y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \dots + \beta_nx_n\]</span></p>
<ul>
<li>The Y is the predicted value</li>
<li>Utilizing the predicted Y value, it finds the best-fit line by iteratively reducing the Mean Squared Error between actual and predicted values.</li>
</ul>
</section>
<section id="lasso-regression" class="level3">
<h3 class="anchored" data-anchor-id="lasso-regression">Lasso Regression</h3>
<ul>
<li><p><strong>Lasso Regression</strong> adds <strong>L1 regularization</strong> to linear regression, shrinking some coefficients to zero for <strong>feature selection</strong> and reducing overfitting.<br>
</p></li>
<li><p><strong>L1 Regularization</strong> (used in Lasso Regression) adds the <strong>absolute values</strong> of the coefficients as a penalty to the cost function.</p>
<ul>
<li>This forces the model to shrink less important coefficients to <strong>zero</strong>, basically <strong>removing features</strong> from the model.</li>
</ul></li>
<li><p><strong>Why L1 Regularization?</strong></p>
<ul>
<li>Reduces <strong>overfitting</strong> by penalizing large coefficients.<br>
</li>
<li>Automatically performs <strong>feature selection</strong>, keeping only the most important predictors.</li>
</ul></li>
<li><p>Same as Linear Regression, it finds the best-fit line by iteratively reducing the Mean Squared Error between actual and predicted values, while also affected by L1 regularization</p></li>
<li><p>I decided to use Lasso Regression to minimize non-important features.</p></li>
</ul>
</section>
</section>
<section id="classification-1" class="level2">
<h2 class="anchored" data-anchor-id="classification-1">Classification</h2>
<section id="logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h3>
<ul>
<li>Logistic regression uses a <strong>probabilistic model</strong> to predict the probability of an instance being <strong>positive or negative</strong>.<br>
</li>
<li>The model:
<ul>
<li>Takes in features.<br>
</li>
<li>Transforms them with weights.<br>
</li>
<li>Utilizes a <strong>sigmoid function</strong> in <strong>Binary Classification</strong> to generate a probability between 0 and 1.<br>
</li>
<li>Utilizes a <strong>softmax function</strong> in Multiclass CLassification to generate probabilities for multiple classes.</li>
</ul></li>
</ul>
</section>
</section>
<section id="decision-tree" class="level2">
<h2 class="anchored" data-anchor-id="decision-tree">Decision Tree</h2>
<ul>
<li>A <strong>decision tree</strong> utilizes feature conditions to split data into smaller and smaller subsets, forming a <strong>tree-like structure</strong>.<br>
</li>
<li>At each node:
<ul>
<li>The tree evaluates conditions to determine the <strong>optimal split</strong>.<br>
</li>
<li>Accuracy metrics like <strong>Gini Index</strong> and <strong>Entropy</strong> measure how well the tree splits data.<br>
</li>
<li><strong>Lower values</strong> indicate a cleaner split.</li>
</ul></li>
<li>By repeatedly splitting and subsetting the data, the decision tree can classify data into both <strong>binary</strong> and <strong>multiclass</strong> targets.</li>
</ul>
<section id="parameters" class="level3">
<h3 class="anchored" data-anchor-id="parameters">Parameters</h3>
<p>The parameters for Decision Trees are utilized to <strong>prevent overfitting</strong> and improve accuracy:</p>
<ul>
<li><code>max_depth</code>: Sets the maximum depth of the tree to prevent overfitting and reduce complexity.<br>
</li>
<li><code>min_samples_split</code>: Sets the minimum number of samples required to split at a node.<br>
</li>
<li><code>min_samples_leaf</code>: Indicates the number of samples required to be in a leaf node.</li>
</ul>
<p><strong>Next step</strong>: help understand this better.</p>
<hr>
</section>
</section>
<section id="random-forest" class="level2">
<h2 class="anchored" data-anchor-id="random-forest">Random Forest</h2>
<ul>
<li><strong>Random Forest</strong> is similar to Decision Trees but builds <strong>multiple trees (ensemble)</strong> and combines predictions.</li>
</ul>
<section id="how-it-works" class="level3">
<h3 class="anchored" data-anchor-id="how-it-works">How It Works:</h3>
<ol type="1">
<li>A decision tree is trained on a <strong>random subset of data</strong> (with replacement).<br>
</li>
<li>At each split, only a <strong>random subset of features</strong> is considered.<br>
</li>
<li>Once multiple trees are established:
<ul>
<li>Each tree votes for a class.<br>
</li>
<li>The majority vote determines the final prediction.</li>
</ul></li>
</ol>
<ul>
<li><strong>Advantages</strong>:
<ul>
<li>Helps prevent overfitting.<br>
</li>
<li>Robust to outliers.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="parameters-1" class="level3">
<h3 class="anchored" data-anchor-id="parameters-1">Parameters</h3>
<p>The parameters for Random Forests are the same as Decision Trees but include:</p>
<ul>
<li><code>n_estimators</code>: Number of decision trees used in the forest.</li>
</ul>
</section>
</section>
<section id="cross-validation" class="level2">
<h2 class="anchored" data-anchor-id="cross-validation">Cross Validation</h2>
<p>Cross Validation is a technique used in <strong>Supervised Learning</strong> to assess how well the model adapts to unseen data.</p>
<ul>
<li>The data is split into k folds of equally sized subjets
<ul>
<li>For each iteration, k-1 folds are used to train the model.</li>
<li>The remaining fold is used for cross validation.</li>
</ul></li>
</ul>
<p>This is repeated k times, and the results are averaged to provide a reliable metric for accuracy.</p>
<section id="why-cross-validation-is-important" class="level3">
<h3 class="anchored" data-anchor-id="why-cross-validation-is-important">Why Cross Validation is Important</h3>
<ul>
<li>Instead of using just 1 train-test split, the model is able to:
<ul>
<li>Train and validate many subset of data.</li>
<li>Ensure the most reliable model performance</li>
</ul></li>
</ul>
</section>
<section id="advantages" class="level3">
<h3 class="anchored" data-anchor-id="advantages">Advantages</h3>
<ul>
<li>Prevents the data from overfitting</li>
<li>Provides powerful evaluation metric for model</li>
</ul>
</section>
<section id="disadvantages" class="level3">
<h3 class="anchored" data-anchor-id="disadvantages">Disadvantages</h3>
<ul>
<li>Complex for large datasets</li>
</ul>
</section>
</section>
</section>
<section id="feature-selection" class="level1">
<h1>Feature Selection</h1>
<p>I chose to <strong>drop features</strong> that did not provide any informative information or provided redundant information.</p>
<p><strong>Dropped Features</strong>: Congressional District, District Name, State, State Abbreviation, Non-Veterans, and Votes Cast.</p>
<p><strong>Reasons</strong>:<br>
- <strong>Congressional District</strong>: A string that held the official title of the district.<br>
- <strong>District Name</strong>: A label that interferes with the model.<br>
- <strong>State</strong>: A string of the full state name - <strong>State Abbreviation</strong>: A string of abbreviated state name - <strong>Non-Veterans</strong>: Redundant because we already have values for veterans. - <strong>Votes Cast</strong>: Caused the model to be too strong, as this feature came from the same data set and represent the same information as our target variable, Voting Rate.</p>
<hr>
<section id="one-hot-encoding" class="level2">
<h2 class="anchored" data-anchor-id="one-hot-encoding">One Hot Encoding</h2>
<p>I chose <strong>not to use One Hot Encoding</strong> for states because:<br>
- It <strong>increased the dimensionality</strong> of my data drastically.<br>
- It caused issues in my regression analysis, with very low accuracy and tendency to overfit.<br>
- I believed the state’s voting policies, culture, and access to voting were already reflected in the numerical features.</p>
<section id="what-is-one-hot-encoding" class="level3">
<h3 class="anchored" data-anchor-id="what-is-one-hot-encoding">What is One Hot Encoding?</h3>
<ul>
<li>Converts categorical features into numerical values.<br>
</li>
<li>A new column is created for each category, with values:
<ul>
<li><code>1</code>: Indicates <strong>True</strong>.<br>
</li>
<li><code>0</code>: Indicates <strong>False</strong>.</li>
</ul></li>
</ul>
</section>
<section id="final-features" class="level3">
<h3 class="anchored" data-anchor-id="final-features">Final Features:</h3>
<p>I chose to leave all the other features as they may influence and indicate different turnouts in the data.</p>
<hr>
<div id="cell-3" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>merged_standard_log_df <span class="op">=</span> pd.read_csv(<span class="st">'../../data/processed-data/merged_standard_log.csv'</span>) </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop unnecessary columns</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>columns_to_drop <span class="op">=</span> [<span class="st">'Nonveterans'</span>, <span class="st">'Congressional_District'</span>, <span class="st">'state_abbreviation'</span>, <span class="st">'District_Name'</span>, <span class="st">'state'</span>, <span class="st">'votes_cast'</span>]</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>processed_df <span class="op">=</span> merged_standard_log_df.drop(columns<span class="op">=</span>columns_to_drop)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final Columns for Modeling:"</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df.columns)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Final Columns for Modeling:
Index(['Total_Population', 'Log_African_American', 'White', 'Log_Asian',
       'Veterans', 'Below_Poverty_Level', 'Log_Median_Household_Income',
       'High_School_Graduate', 'Bachelors_Degree_or_Higher',
       'Households_with_Computers', 'Households_with_Internet',
       'Log_American_Indian_and_Alaska_Native',
       'Log_Native_Hawaiian_and_Pacific_Islander', 'Median_Age',
       'citizen_voting_age_population_estimate', 'voting_rate_estimate'],
      dtype='object')</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="regression-2" class="level1">
<h1>Regression</h1>
<p>I set the <strong>Voting Rate Estimate</strong> as the <strong>target variable</strong>, All other variables are used as features to train the model.</p>
<p><strong>Train-Test Split</strong>:<br>
- <code>X_train</code>: 80% of the features.<br>
- <code>X_test</code>: 20% of the features.<br>
- <code>y_train</code>: Voting Rate Estimate for 80% of the data.<br>
- <code>y_test</code>: Voting Rate Estimate for the other 20%.</p>
<hr>
<div id="cell-5" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'voting_rate_estimate'</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop the target from the features</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> processed_df.drop(columns<span class="op">=</span>[target])</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    features, processed_df[target], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the model</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>linear_reg <span class="op">=</span> LinearRegression()</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>linear_reg.fit(X_train, y_train)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> linear_reg.predict(X_train)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> linear_reg.predict(X_test)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>mse_train <span class="op">=</span> mean_squared_error(y_train, y_pred_train)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>mse_test <span class="op">=</span> mean_squared_error(y_test, y_pred_test)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>r2_train <span class="op">=</span> r2_score(y_train, y_pred_train)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>r2_test <span class="op">=</span> r2_score(y_test, y_pred_test)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE and MAE</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>rmse_train <span class="op">=</span> np.sqrt(mse_train)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>rmse_test <span class="op">=</span> np.sqrt(mse_test)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>mae_train <span class="op">=</span> mean_absolute_error(y_train, y_pred_train)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>mae_test <span class="op">=</span> mean_absolute_error(y_test, y_pred_test)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train RMSE: </span><span class="sc">{</span>rmse_train<span class="sc">}</span><span class="ss">, MAE: </span><span class="sc">{</span>mae_train<span class="sc">}</span><span class="ss">, R^2: </span><span class="sc">{</span>r2_train<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test RMSE: </span><span class="sc">{</span>rmse_test<span class="sc">}</span><span class="ss">, MAE: </span><span class="sc">{</span>mae_test<span class="sc">}</span><span class="ss">, R^2: </span><span class="sc">{</span>r2_test<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a parity plot</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>plt.scatter(y_test, y_pred_test, alpha<span class="op">=</span><span class="fl">0.7</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>, label<span class="op">=</span><span class="st">'Test Data'</span>)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>plt.scatter(y_train, y_pred_train, alpha<span class="op">=</span><span class="fl">0.7</span>, edgecolors<span class="op">=</span><span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Train Data'</span>)</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>plt.plot([y_train.<span class="bu">min</span>(), y_train.<span class="bu">max</span>()], [y_train.<span class="bu">min</span>(), y_train.<span class="bu">max</span>()], color<span class="op">=</span><span class="st">'blue'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Perfect Fit'</span>)</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Actual Values"</span>)</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Predicted Values"</span>)</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Parity Plot"</span>)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Train RMSE: 0.5652380229553347, MAE: 0.43493826352937637, R^2: 0.6765001127743566
Test RMSE: 0.5709603067729877, MAE: 0.4656940110653836, R^2: 0.6885077504960029</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-3-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="linear-regression-feature-importance" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-feature-importance">Linear Regression Feature Importance</h2>
<div id="cell-7" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># After training the model</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>coefficients <span class="op">=</span> linear_reg.coef_  <span class="co"># Get coefficients</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> X_train.columns  <span class="co"># Get feature names</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine coefficients with feature names</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: feature_names,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: coefficients</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>}).sort_values(by<span class="op">=</span><span class="st">'Coefficient'</span>, ascending<span class="op">=</span><span class="va">False</span>, key<span class="op">=</span><span class="bu">abs</span>)  <span class="co"># Sort by absolute value</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Display top predictors</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top Predictors for Linear Regression:"</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(importance_df.head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Top Predictors for Linear Regression:
                                     Feature  Coefficient
7                       High_School_Graduate    -0.467101
5                        Below_Poverty_Level    -0.364904
10                  Households_with_Internet     0.334820
14    citizen_voting_age_population_estimate     0.291538
13                                Median_Age     0.187899
3                                  Log_Asian    -0.159315
9                  Households_with_Computers    -0.096102
12  Log_Native_Hawaiian_and_Pacific_Islander    -0.060645
4                                   Veterans    -0.044753
1                       Log_African_American    -0.033687</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>plt.barh(importance_df[<span class="st">'Feature'</span>], importance_df[<span class="st">'Coefficient'</span>])</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Coefficient Value"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature"</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Linear Regression Coefficients"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()  <span class="co"># Reverse order for better readability</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>he biggest coefficents was High School Graduate and Poverty Level, both with negative coefficients. Households with Internet, Voting Age population, and MedianAge were the next biggest coefficiences, and were all positive.</p>
</section>
<section id="linear-regression-accuracy-analysis" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-accuracy-analysis">Linear Regression Accuracy Analysis</h2>
<div id="cell-10" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>data_metrics <span class="op">=</span> {</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Metric"</span>: [<span class="st">"RMSE"</span>, <span class="st">"MAE"</span>, <span class="st">"R^2"</span>],</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Train"</span>: [<span class="fl">0.5652380229553347</span>, <span class="fl">0.43493826352937637</span>, <span class="fl">0.6765001127743566</span>],</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Test"</span>: [<span class="fl">0.5709603067729877</span>, <span class="fl">0.4656940110653836</span>, <span class="fl">0.6885077504960029</span>]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>df_metrics <span class="op">=</span> pd.DataFrame(data_metrics)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  Metric     Train      Test
0   RMSE  0.565238  0.570960
1    MAE  0.434938  0.465694
2    R^2  0.676500  0.688508</code></pre>
</div>
</div>
<p>Conducting the Linear regression analysis, the data accuracy metrics indicated that our model performed well on both sets of data.</p>
<ul>
<li><strong>Train RMSE</strong> had a value of <strong>0.565</strong>, and <strong>Test RMSE</strong> had a value of <strong>0.571</strong>.
<ul>
<li>This indicates that, on average, when testing, the model’s prediction of voting rate was <strong>0.571 standardized units</strong> from the actual value.<br>
</li>
<li>The model had similar RMSE values for the test set and the training set, indicating the model is doing well in applying its training to unseen data.</li>
</ul></li>
<li><strong>Train MAE</strong> and <strong>Test MAE</strong> also indicated the model did very well:
<ul>
<li><strong>Train MAE</strong>: <strong>0.435</strong><br>
</li>
<li><strong>Test MAE</strong>: <strong>0.466</strong><br>
</li>
<li>This shows that the average absolute difference between predicted and actual values is very small.</li>
</ul></li>
<li><strong>R² values</strong> for both the Train and Test sets indicated that more than half of the variance is explained by the model:
<ul>
<li><strong>Train R²</strong>: <strong>0.677</strong><br>
</li>
<li><strong>Test R²</strong>: <strong>0.689</strong><br>
</li>
<li>This means that <strong>68.9% of the variance</strong> in the test data can be explained.<br>
</li>
<li>The Test R² had a slightly higher (more accurate) value than the Train R², suggesting that the model is <strong>very good at predicting unseen values</strong>.</li>
</ul></li>
<li>The <strong>parity plot</strong> of the <strong>cross-validated data</strong> looks very similar to the non-cross-validated model, indicating that our model is <strong>moderately accurate</strong> in predicting voting rates.</li>
</ul>
</section>
<section id="cross-validation-1" class="level2">
<h2 class="anchored" data-anchor-id="cross-validation-1">Cross Validation</h2>
<div id="cell-12" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score, cross_val_predict</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> make_scorer, mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define scoring metric (negative MSE for compatibility with cross_val_score)</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>scoring <span class="op">=</span> make_scorer(mean_squared_error, greater_is_better<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform cross-validation (5-fold)</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>cv_scores <span class="op">=</span> cross_val_score(linear_reg, features, processed_df[target], cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span>scoring)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert negative MSE to positive</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>cv_mse_scores <span class="op">=</span> <span class="op">-</span>cv_scores</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>cv_rmse_scores <span class="op">=</span> [score <span class="op">**</span> <span class="fl">0.5</span> <span class="cf">for</span> score <span class="kw">in</span> cv_mse_scores]  <span class="co"># RMSE</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross-validated predictions (for calculating additional metrics)</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>cv_predictions <span class="op">=</span> cross_val_predict(linear_reg, features, processed_df[target], cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute additional metrics (MAE and R^2)</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>cv_mae <span class="op">=</span> mean_absolute_error(processed_df[target], cv_predictions)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>cv_r2 <span class="op">=</span> r2_score(processed_df[target], cv_predictions)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cross-Validation RMSE Scores: </span><span class="sc">{</span>cv_rmse_scores<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average Cross-Validation RMSE: </span><span class="sc">{</span>np<span class="sc">.</span>mean(cv_rmse_scores)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cross-Validation MAE: </span><span class="sc">{</span>cv_mae<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cross-Validation R^2: </span><span class="sc">{</span>cv_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Parity Plot for Cross-Validation</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>plt.scatter(processed_df[target], cv_predictions, alpha<span class="op">=</span><span class="fl">0.7</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>, label<span class="op">=</span><span class="st">'Cross-Validation Predictions'</span>)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>plt.plot([processed_df[target].<span class="bu">min</span>(), processed_df[target].<span class="bu">max</span>()],</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>         [processed_df[target].<span class="bu">min</span>(), processed_df[target].<span class="bu">max</span>()], color<span class="op">=</span><span class="st">'blue'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Perfect Fit'</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Actual Values"</span>)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Predicted Values"</span>)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Parity Plot - Cross-Validation"</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Cross-Validation RMSE Scores: [0.4842817971199596, 0.5899720563378389, 0.5496217683565214, 0.6775249748666702, 0.6415611537057684]
Average Cross-Validation RMSE: 0.5886
Cross-Validation MAE: 0.4564
Cross-Validation R^2: 0.6492</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-7-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="cross-validation-linear-regression-accuracy-analysis" class="level2">
<h2 class="anchored" data-anchor-id="cross-validation-linear-regression-accuracy-analysis">Cross Validation Linear Regression Accuracy Analysis</h2>
<div id="cell-14" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>data_cross_validation <span class="op">=</span> {</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Metric"</span>: [<span class="st">"RMSE (Fold 1)"</span>, <span class="st">"RMSE (Fold 2)"</span>, <span class="st">"RMSE (Fold 3)"</span>, <span class="st">"RMSE (Fold 4)"</span>, <span class="st">"RMSE (Fold 5)"</span>, </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>               <span class="st">"Average RMSE"</span>, <span class="st">"MAE"</span>, <span class="st">"R^2"</span>],</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Score"</span>: [<span class="fl">0.4842817971199596</span>, <span class="fl">0.5899720563378389</span>, <span class="fl">0.5496217683565214</span>, <span class="fl">0.6775249748666702</span>, </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>              <span class="fl">0.6415611537057684</span>, <span class="fl">0.5886</span>, <span class="fl">0.4564</span>, <span class="fl">0.6492</span>]</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the DataFrame for Cross-Validation metrics</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>df_cross_validation <span class="op">=</span> pd.DataFrame(data_cross_validation)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_cross_validation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          Metric     Score
0  RMSE (Fold 1)  0.484282
1  RMSE (Fold 2)  0.589972
2  RMSE (Fold 3)  0.549622
3  RMSE (Fold 4)  0.677525
4  RMSE (Fold 5)  0.641561
5   Average RMSE  0.588600
6            MAE  0.456400
7            R^2  0.649200</code></pre>
</div>
</div>
<p>Conducting Cross Validation Linear regression analysis, the data accuracy metrics indicated that our model performed <strong>similarly</strong> to the non-cross-validated Log Regression model.</p>
<ul>
<li>The <strong>average RMSE</strong> had a value of <strong>0.58</strong>, slightly higher than <strong>0.565</strong> from the non-cross-validated model.<br>
</li>
<li>The model also had an <strong>MAE</strong> of <strong>0.45</strong> and R^2 value of 0.69, both higher values than without cross validating.</li>
</ul>
<p>The Cross Validation Accuracy Metrics tells us that there was not a big difference in accuracy between this model and the model that didn’t utilize Cross Validation.</p>
<hr>
</section>
<section id="lasso-regression-1" class="level2">
<h2 class="anchored" data-anchor-id="lasso-regression-1">Lasso Regression</h2>
<div id="cell-16" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the target and features</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'voting_rate_estimate'</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> processed_df.drop(columns<span class="op">=</span>[target])</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    features, processed_df[target], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Lasso Regression with alpha (regularization strength)</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>lasso_reg <span class="op">=</span> Lasso(alpha<span class="op">=</span><span class="fl">0.01</span>, random_state<span class="op">=</span><span class="dv">42</span>)  <span class="co"># You can tune 'alpha' for stronger or weaker regularization</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>lasso_reg.fit(X_train, y_train)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> lasso_reg.predict(X_train)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> lasso_reg.predict(X_test)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>mse_train <span class="op">=</span> mean_squared_error(y_train, y_pred_train)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>mse_test <span class="op">=</span> mean_squared_error(y_test, y_pred_test)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>r2_train <span class="op">=</span> r2_score(y_train, y_pred_train)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>r2_test <span class="op">=</span> r2_score(y_test, y_pred_test)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE and MAE</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>rmse_train <span class="op">=</span> np.sqrt(mse_train)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>rmse_test <span class="op">=</span> np.sqrt(mse_test)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>mae_train <span class="op">=</span> mean_absolute_error(y_train, y_pred_train)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>mae_test <span class="op">=</span> mean_absolute_error(y_test, y_pred_test)</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Print evaluation metrics</span></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Lasso Regression Results:"</span>)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train RMSE: </span><span class="sc">{</span>rmse_train<span class="sc">:.4f}</span><span class="ss">, MAE: </span><span class="sc">{</span>mae_train<span class="sc">:.4f}</span><span class="ss">, R²: </span><span class="sc">{</span>r2_train<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test RMSE: </span><span class="sc">{</span>rmse_test<span class="sc">:.4f}</span><span class="ss">, MAE: </span><span class="sc">{</span>mae_test<span class="sc">:.4f}</span><span class="ss">, R²: </span><span class="sc">{</span>r2_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Display coefficients</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>lasso_coefficients <span class="op">=</span> pd.DataFrame({</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: lasso_reg.coef_</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>}).sort_values(by<span class="op">=</span><span class="st">'Coefficient'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Parity Plot</span></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>plt.scatter(y_test, y_pred_test, alpha<span class="op">=</span><span class="fl">0.7</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>, label<span class="op">=</span><span class="st">'Test Data'</span>)</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>plt.scatter(y_train, y_pred_train, alpha<span class="op">=</span><span class="fl">0.7</span>, edgecolors<span class="op">=</span><span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Train Data'</span>)</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>plt.plot([y_train.<span class="bu">min</span>(), y_train.<span class="bu">max</span>()], [y_train.<span class="bu">min</span>(), y_train.<span class="bu">max</span>()], color<span class="op">=</span><span class="st">'blue'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Perfect Fit'</span>)</span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Actual Values"</span>)</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Predicted Values"</span>)</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Lasso Regression Parity Plot"</span>)</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Lasso Regression Results:
Train RMSE: 0.5673, MAE: 0.4337, R²: 0.6741
Test RMSE: 0.5767, MAE: 0.4691, R²: 0.6822</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="lasso-regression-accuracy-analysis" class="level2">
<h2 class="anchored" data-anchor-id="lasso-regression-accuracy-analysis">Lasso Regression Accuracy Analysis</h2>
<div id="cell-18" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>lasso_results <span class="op">=</span> {</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Metric"</span>: [<span class="st">"RMSE"</span>, <span class="st">"MAE"</span>, <span class="st">"R²"</span>],</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Train"</span>: [<span class="fl">0.5673</span>, <span class="fl">0.4337</span>, <span class="fl">0.6741</span>],</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Test"</span>: [<span class="fl">0.5767</span>, <span class="fl">0.4691</span>, <span class="fl">0.6822</span>]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrame</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>lasso_results_df <span class="op">=</span> pd.DataFrame(lasso_results)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lasso_results_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  Metric   Train    Test
0   RMSE  0.5673  0.5767
1    MAE  0.4337  0.4691
2     R²  0.6741  0.6822</code></pre>
</div>
</div>
<p>Conducting the <strong>Lasso Regression analysis</strong>, the data accuracy metrics indicated that our model perfomed similar to linear regression.</p>
<ul>
<li><strong>Train RMSE</strong> had a value of <strong>0.567</strong>, and <strong>Test RMSE</strong> had a value of <strong>0.577</strong>.
<ul>
<li>This indicates that, on average, when testing, the model’s prediction was <strong>0.577 standardized units</strong> from the actual value.<br>
</li>
<li>The model had similar RMSE values for the test set and the training set, indicating the model is doing well in applying its training to unseen data.</li>
</ul></li>
<li><strong>Train MAE</strong> and <strong>Test MAE</strong> also indicated the model performed well:
<ul>
<li><strong>Train MAE</strong>: <strong>0.434</strong><br>
</li>
<li><strong>Test MAE</strong>: <strong>0.469</strong><br>
</li>
<li>This shows that the average absolute difference between predicted and actual values is very small.</li>
</ul></li>
<li><strong>R² values</strong> for both the Train and Test sets showed that a significant proportion of the variance is explained by the model:
<ul>
<li><strong>Train R²</strong>: <strong>0.674</strong><br>
</li>
<li><strong>Test R²</strong>: <strong>0.682</strong><br>
</li>
<li>This means that <strong>68.2% of the variance</strong> in the test data can be explained.<br>
</li>
<li>The Lasso R² value was slightly lower value than the Linear Regressioin R² value(0.0682).</li>
</ul></li>
<li>Similar to Linear Regression, The <strong>parity plot</strong> of the <strong>cross-validated data</strong> reflects a consistent alignment of predicted and actual values, suggesting that the model is <strong>accurate and reliable</strong> for predicting the target variable.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>These metrics tell us that our model is performing <strong>moderately well</strong> with both sets of data, as well as with and without cross validation.</p>
<ul>
<li>For both methods, both <strong>RMSE</strong> and <strong>MAE</strong> values are moderately close to zero.<br>
</li>
<li>Both methods have a <strong>moderately high R² value</strong>, indicating our predicted values are close to actual values.<br>
</li>
<li>Linear Regression, Lasso Regression, and implimenting Cross Validation all provided almost identical accuracy metrics, with Linear regression having the lowest RMSE value , and cross validated linear regression having the lowest MAE and R^2 value.</li>
</ul>
<p>This tells us that the model has begun to learn trends and relationships in the data to predict voting rates with <strong>moderately high accuracy</strong>.</p>
</section>
<section id="real-world-application" class="level2">
<h2 class="anchored" data-anchor-id="real-world-application">Real World Application</h2>
<p>This model has implications for real-world use. However, with a prediction error of <strong>0.57 standardized units</strong>, the model still requires further improvement and calibration before being reliably applied in real voting scenarios. Doing this will allow policymakers and analysts to gain insights and make educated decisions.</p>
</section>
</section>
<section id="binary-classification-1" class="level1">
<h1>Binary Classification</h1>
<section id="target-selection" class="level2">
<h2 class="anchored" data-anchor-id="target-selection">Target Selection</h2>
<p>I chose my Binary Classification target as ‘High Voting Rate’ and ‘Low Voting Rate’. Districts were labeled as High Voting Rate if the voting rate exceeded the mean voting rate.</p>
</section>
<section id="log-regression-binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="log-regression-binary-classification">Log Regression Binary Classification</h2>
<div id="cell-20" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix, roc_auc_score, roc_curve</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>merged_standard_log_df[<span class="st">'High_Voting_Rate'</span>] <span class="op">=</span> (merged_standard_log_df[<span class="st">'voting_rate_estimate'</span>] <span class="op">&gt;</span> merged_standard_log_df[<span class="st">'voting_rate_estimate'</span>].median()).astype(<span class="bu">int</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Define target and features</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>binary_target <span class="op">=</span> <span class="st">'High_Voting_Rate'</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure High_Voting_Rate is included in processed_df</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>processed_df[<span class="st">'High_Voting_Rate'</span>] <span class="op">=</span> merged_standard_log_df[<span class="st">'High_Voting_Rate'</span>]</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove binary and regression targets from features</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> processed_df.drop(columns<span class="op">=</span>[binary_target, <span class="st">'voting_rate_estimate'</span>])</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    features, processed_df[binary_target], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Logistic Regression model</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>log_reg <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>log_reg.fit(X_train, y_train)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> log_reg.predict(X_train) <span class="co">#predict classes for training set </span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> log_reg.predict(X_test) <span class="co">#predict classes for test set </span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>y_prob_test <span class="op">=</span> log_reg.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probabilities for ROC curve</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report (Test Data):"</span>)</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_test))</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred_test)</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, xticklabels<span class="op">=</span>[<span class="st">'Low'</span>, <span class="st">'High'</span>], yticklabels<span class="op">=</span>[<span class="st">'Low'</span>, <span class="st">'High'</span>])</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Confusion Matrix"</span>)</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Predicted"</span>)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Actual"</span>)</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC Curve</span></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, y_prob_test)</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> roc_auc_score(y_test, y_prob_test)</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="ss">f'ROC Curve (AUC = </span><span class="sc">{</span>roc_auc<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>, label<span class="op">=</span><span class="st">"Random Classifier"</span>)</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Receiver Operating Characteristic (ROC) Curve"</span>)</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Classification Report (Test Data):
              precision    recall  f1-score   support

           0       0.89      0.72      0.79        43
           1       0.77      0.91      0.83        44

    accuracy                           0.82        87
   macro avg       0.83      0.82      0.81        87
weighted avg       0.83      0.82      0.81        87
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-11-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="log-binary-classification-accuracy-analysis" class="level2">
<h2 class="anchored" data-anchor-id="log-binary-classification-accuracy-analysis">Log Binary Classification Accuracy Analysis</h2>
<div id="cell-22" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>data_classification_report <span class="op">=</span> {</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Class"</span>: [<span class="dv">0</span>, <span class="dv">1</span>, <span class="st">"accuracy"</span>, <span class="st">"macro avg"</span>],</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Precision"</span>: [<span class="fl">0.89</span>, <span class="fl">0.77</span>, <span class="va">None</span>, <span class="fl">0.83</span>],</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Recall"</span>: [<span class="fl">0.72</span>, <span class="fl">0.91</span>, <span class="va">None</span>, <span class="fl">0.82</span>],</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"F1-Score"</span>: [<span class="fl">0.79</span>, <span class="fl">0.83</span>, <span class="fl">0.82</span>, <span class="fl">0.81</span>],</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Support"</span>: [<span class="dv">43</span>, <span class="dv">44</span>, <span class="dv">87</span>, <span class="dv">87</span>]</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the DataFrame for the classification report</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>df_classification_report <span class="op">=</span> pd.DataFrame(data_classification_report)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the DataFrame</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_classification_report)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       Class  Precision  Recall  F1-Score  Support
0          0       0.89    0.72      0.79       43
1          1       0.77    0.91      0.83       44
2   accuracy        NaN     NaN      0.82       87
3  macro avg       0.83    0.82      0.81       87</code></pre>
</div>
</div>
<section id="precision-1" class="level3">
<h3 class="anchored" data-anchor-id="precision-1">Precision</h3>
<p>The accuracy metrics for our model showed that <strong>precision scores</strong> were very high, with values of <strong>89%</strong> for <strong>Low Voting Rate</strong> and <strong>77%</strong> for <strong>High Voting Rate</strong>.</p>
</section>
<section id="recall-1" class="level3">
<h3 class="anchored" data-anchor-id="recall-1">Recall</h3>
<p><strong>Recall scores</strong> were also very high, with <strong>91%</strong> for <strong>High Voting Rate</strong> and <strong>72%</strong> for <strong>Low Voting Rate</strong>, indicating that the model captured most true positives.</p>
</section>
<section id="f1" class="level3">
<h3 class="anchored" data-anchor-id="f1">F1</h3>
<p>The <strong>F1 score</strong> was <strong>83%</strong> for <strong>High Voting Rate</strong>, reflecting a good balance between <strong>Precision</strong> and <strong>Recall</strong>. The overall accuracy was also <strong>82%</strong>, showcasing a model that is effective in distinguishing between two classes.</p>
</section>
<section id="confusion-matrix" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix">Confusion Matrix</h3>
<p>The <strong>Confusion Matrix</strong> shows the results of the Log Regression Binary Classification model:</p>
<ul>
<li>The model correctly predicted <strong>40 values</strong> of <strong>‘High Voting Rate’</strong> (True Positives).<br>
</li>
<li>The model correctly predicted <strong>31 values</strong> of <strong>‘Low Voting Rate’</strong> (True Negatives).<br>
</li>
<li>The model incorrectly classified <strong>12 values</strong> as <strong>‘High Voting Rate’</strong> when they were actually low (<strong>False Positive</strong>).<br>
</li>
<li>The model incorrectly classified <strong>4 values</strong> as <strong>‘Low Voting Rate’</strong> when they were actually high (<strong>False Negative</strong>).</li>
</ul>
</section>
<section id="roc-curve-1" class="level3">
<h3 class="anchored" data-anchor-id="roc-curve-1">ROC Curve</h3>
<p>The <strong>ROC Curve</strong> showcases an <strong>AUC score of 0.87</strong>, indicating an accurate model that distinguishes between Low and High voting rates.</p>
<ul>
<li>The curve rises steeply, indicating the model quickly achieves a high <strong>True Positive Rate</strong> with low <strong>False Positive Rate</strong>.<br>
</li>
<li>Furthermore, the curve is <strong>significantly higher</strong> than the diagonal baseline, showing that the model is better than a random classifier.</li>
</ul>
</section>
</section>
<section id="decision-tree-binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="decision-tree-binary-classification">Decision Tree Binary Classification</h2>
<div id="cell-24" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Decision Tree model</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>dt_clf <span class="op">=</span> DecisionTreeClassifier(</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    criterion<span class="op">=</span><span class="st">"gini"</span>,        <span class="co"># Use 'gini' or 'entropy' to measure split quality</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">5</span>,             <span class="co"># Maximum depth of the tree to prevent overfitting</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">10</span>,    <span class="co"># Minimum samples needed to split an internal node</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">5</span>,      <span class="co"># Minimum samples in each leaf node</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>          <span class="co"># Ensure reproducibility</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the Decision Tree</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>dt_clf.fit(X_train, y_train)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> dt_clf.predict(X_train)  <span class="co"># Predict on training data</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> dt_clf.predict(X_test)    <span class="co"># Predict on test data</span></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Decision Tree - Classification Report (Binary):"</span>)</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_test))</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred_test)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, xticklabels<span class="op">=</span>[<span class="st">'Low'</span>, <span class="st">'High'</span>], yticklabels<span class="op">=</span>[<span class="st">'Low'</span>, <span class="st">'High'</span>])</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Decision Tree - Confusion Matrix"</span>)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Predicted"</span>)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Actual"</span>)</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Decision Tree - Classification Report (Binary):
              precision    recall  f1-score   support

           0       0.76      0.51      0.61        43
           1       0.64      0.84      0.73        44

    accuracy                           0.68        87
   macro avg       0.70      0.68      0.67        87
weighted avg       0.70      0.68      0.67        87
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-13-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="decision-tree-binary-classification-accuracy-analysis" class="level2">
<h2 class="anchored" data-anchor-id="decision-tree-binary-classification-accuracy-analysis">Decision Tree Binary Classification Accuracy Analysis</h2>
<div id="cell-26" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>data_decision_tree_binary <span class="op">=</span> {</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Class"</span>: [<span class="dv">0</span>, <span class="dv">1</span>, <span class="st">"accuracy"</span>, <span class="st">"macro avg"</span>],</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Precision"</span>: [<span class="fl">0.76</span>, <span class="fl">0.64</span>, <span class="va">None</span>, <span class="fl">0.70</span>],</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Recall"</span>: [<span class="fl">0.51</span>, <span class="fl">0.84</span>, <span class="va">None</span>, <span class="fl">0.68</span>],</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"F1-Score"</span>: [<span class="fl">0.61</span>, <span class="fl">0.73</span>, <span class="fl">0.68</span>, <span class="fl">0.67</span>],</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Support"</span>: [<span class="dv">43</span>, <span class="dv">44</span>, <span class="dv">87</span>, <span class="dv">87</span>]</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the DataFrame for the Decision Tree binary report</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>df_decision_tree_binary <span class="op">=</span> pd.DataFrame(data_decision_tree_binary)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the DataFrame</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_decision_tree_binary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       Class  Precision  Recall  F1-Score  Support
0          0       0.76    0.51      0.61       43
1          1       0.64    0.84      0.73       44
2   accuracy        NaN     NaN      0.68       87
3  macro avg       0.70    0.68      0.67       87</code></pre>
</div>
</div>
<section id="precision-2" class="level3">
<h3 class="anchored" data-anchor-id="precision-2">Precision</h3>
<p>The accuracy metrics for our model showed that <strong>precision scores</strong> were moderately high but varied, with values of <strong>76%</strong> for <strong>Low Voting Rate</strong> and <strong>76%</strong> for <strong>High Voting Rate</strong>. These two scores were also <strong>lower</strong> than Binary Classification with Log Regression.</p>
</section>
<section id="recall-2" class="level3">
<h3 class="anchored" data-anchor-id="recall-2">Recall</h3>
<p><strong>Recall scores</strong> showcased the same pattern of varied values for different classes, with <strong>84%</strong> for <strong>High Voting Rate</strong> and <strong>51%</strong> for <strong>Low Voting Rate</strong>.<br>
- This indicates that the model captured most <strong>true positives</strong> for High Voting Rates but struggled with Low Voting Rates.</p>
</section>
<section id="f1-1" class="level3">
<h3 class="anchored" data-anchor-id="f1-1">F1</h3>
<p>The <strong>F1 score</strong> was <strong>73%</strong> for <strong>High Voting Rate</strong>, reflecting a pretty good balance between <strong>Precision</strong> and <strong>Recall</strong>.<br>
- The overall accuracy was <strong>68%</strong>, showcasing a model that is <strong>moderately successful</strong> in distinguishing between two classes.<br>
- These values were also <strong>lower</strong> than Binary Classification with Log Regression.</p>
</section>
<section id="confusion-matrix-1" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix-1">Confusion Matrix</h3>
<p>The <strong>Confusion Matrix</strong> shows the results of the Log Regression Binary Classification model:</p>
<ul>
<li>The model correctly predicted <strong>37 values</strong> of <strong>‘High Voting Rate’</strong> (True Positives).<br>
</li>
<li>The model correctly predicted <strong>22 values</strong> of <strong>‘Low Voting Rate’</strong> (True Negatives).<br>
</li>
<li>The model incorrectly classified <strong>21 values</strong> as <strong>‘High Voting Rate’</strong> when they were actually low (<strong>False Positive</strong>).<br>
</li>
<li>The model incorrectly classified <strong>7 values</strong> as <strong>‘Low Voting Rate’</strong> when they were actually high (<strong>False Negative</strong>).</li>
</ul>
</section>
<section id="decision-tree-1" class="level3">
<h3 class="anchored" data-anchor-id="decision-tree-1">Decision Tree</h3>
<div id="cell-28" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> plot_tree</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the Decision Tree</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">15</span>))  <span class="co"># Adjust size for better readability</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>plot_tree(</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    dt_clf, </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    feature_names<span class="op">=</span>X_train.columns,  <span class="co"># Use feature names from your dataset</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    class_names<span class="op">=</span>[<span class="st">'Low'</span>, <span class="st">'High'</span>],   <span class="co"># Binary class names</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    filled<span class="op">=</span><span class="va">True</span>,                   <span class="co"># Fill nodes with colors</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    rounded<span class="op">=</span><span class="va">True</span>,                  <span class="co"># Rounded corners for better visualization</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    fontsize<span class="op">=</span><span class="dv">10</span>                    <span class="co"># Adjust font size for readability</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Binary Decision Tree Visualization"</span>)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The first split is based on if Bachelors_Degree_or_Higher&lt; -0.719, with a Gini index of 0.5. This indicates an impure split, and we can see that with the almost perfectly symmetric data values.</p>
<p>If the data point is less than -0.719, it goes left, if it is more than -0.719, it goes right. It then gets asked another criteria, and the data splits.</p>
</section>
</section>
<section id="random-forest-binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-binary-classification">Random Forest Binary Classification</h2>
<div id="cell-30" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix, roc_auc_score, roc_curve</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Random Forest model</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>rf_clf <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">10</span>,      <span class="co"># Maximum depth of trees (to avoid overfitting)</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,   <span class="co"># For reproducibility</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span><span class="st">'balanced'</span>  <span class="co"># Handle any imbalance in data</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>rf_clf.fit(X_train, y_train)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> rf_clf.predict(X_train)  <span class="co"># Predict on training data</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> rf_clf.predict(X_test)  <span class="co"># Predict on test data</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>y_prob_test <span class="op">=</span> rf_clf.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probabilities for ROC curve</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest - Classification Report (Test Data):"</span>)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_test))</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred_test)</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, xticklabels<span class="op">=</span>[<span class="st">'Low'</span>, <span class="st">'High'</span>], yticklabels<span class="op">=</span>[<span class="st">'Low'</span>, <span class="st">'High'</span>])</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Random Forest - Confusion Matrix"</span>)</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Predicted"</span>)</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Actual"</span>)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest - Classification Report (Test Data):
              precision    recall  f1-score   support

           0       0.87      0.79      0.83        43
           1       0.81      0.89      0.85        44

    accuracy                           0.84        87
   macro avg       0.84      0.84      0.84        87
weighted avg       0.84      0.84      0.84        87
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-16-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="random-forest-binary-classification-feature-importance" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-binary-classification-feature-importance">Random Forest Binary Classification Feature Importance</h2>
<div id="cell-32" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Access feature importance</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>feature_importances <span class="op">=</span> rf_clf.feature_importances_</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine with feature names</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: feature_importances</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>}).sort_values(by<span class="op">=</span><span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot feature importance</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>plt.barh(importance_df[<span class="st">'Feature'</span>], importance_df[<span class="st">'Importance'</span>])</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature Importance"</span>)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature"</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Random Forest Feature Importance"</span>)</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()  <span class="co"># Reverse order for better readability</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Display top predictors</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(importance_df.head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                   Feature  Importance
8               Bachelors_Degree_or_Higher    0.131918
5                      Below_Poverty_Level    0.116159
10                Households_with_Internet    0.105330
6              Log_Median_Household_Income    0.102438
9                Households_with_Computers    0.091314
13                              Median_Age    0.060863
1                     Log_African_American    0.056157
4                                 Veterans    0.053923
14  citizen_voting_age_population_estimate    0.051646
7                     High_School_Graduate    0.046506</code></pre>
</div>
</div>
<p>The Random Forest feature importance quantifies how much each feature contributed to the random forest. Each value is computed by how much each feature reduced the Gini score (error).</p>
<p>For <strong>Binary Classification</strong>, the Random Forest deemed Bachelors Degree or Higher, Poverty Level, Internet Accecss, and Median Household Income as the most defining features in making splits.</p>
</section>
<section id="random-forest-binary-classification-accuracy-analysis" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-binary-classification-accuracy-analysis">Random Forest Binary Classification Accuracy Analysis</h2>
<div id="cell-34" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>data_random_forest_updated <span class="op">=</span> {</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Class"</span>: [<span class="dv">0</span>, <span class="dv">1</span>, <span class="st">"accuracy"</span>, <span class="st">"macro avg"</span>],</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Precision"</span>: [<span class="fl">0.87</span>, <span class="fl">0.81</span>, <span class="va">None</span>, <span class="fl">0.84</span>],</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Recall"</span>: [<span class="fl">0.79</span>, <span class="fl">0.89</span>, <span class="va">None</span>, <span class="fl">0.84</span>],</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"F1-Score"</span>: [<span class="fl">0.83</span>, <span class="fl">0.85</span>, <span class="fl">0.84</span>, <span class="fl">0.84</span>],</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Support"</span>: [<span class="dv">43</span>, <span class="dv">44</span>, <span class="dv">87</span>, <span class="dv">87</span>]</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the DataFrame for the updated Random Forest report</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>df_random_forest_binary <span class="op">=</span> pd.DataFrame(data_random_forest_updated)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_random_forest_binary)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the DataFrame</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       Class  Precision  Recall  F1-Score  Support
0          0       0.87    0.79      0.83       43
1          1       0.81    0.89      0.85       44
2   accuracy        NaN     NaN      0.84       87
3  macro avg       0.84    0.84      0.84       87</code></pre>
</div>
</div>
<section id="precision-3" class="level3">
<h3 class="anchored" data-anchor-id="precision-3">Precision</h3>
<p>The accuracy metrics for our model showed that <strong>precision scores</strong> were moderately high but varied, with values of:<br>
- <strong>76%</strong> for <strong>Low Voting Rate</strong><br>
- <strong>76%</strong> for <strong>High Voting Rate</strong></p>
<p>These two scores were also <strong>lower</strong> than Binary Classification with Log Regression.</p>
<hr>
</section>
<section id="recall-3" class="level3">
<h3 class="anchored" data-anchor-id="recall-3">Recall</h3>
<p><strong>Recall scores</strong> showcased the same pattern of varied values for different classes:<br>
- <strong>84%</strong> for <strong>High Voting Rate</strong><br>
- <strong>51%</strong> for <strong>Low Voting Rate</strong></p>
<p>This indicates that the model captured most <strong>true positives</strong> for High Voting Rates but struggled with Low Voting Rates.</p>
<hr>
</section>
<section id="f1-2" class="level3">
<h3 class="anchored" data-anchor-id="f1-2">F1</h3>
<p>The <strong>F1 score</strong> was <strong>73%</strong> for <strong>High Voting Rate</strong>, reflecting a pretty good balance between <strong>Precision</strong> and <strong>Recall</strong>.<br>
- The overall accuracy was <strong>68%</strong>, showcasing a model that is <strong>moderately successful</strong> in distinguishing between two classes.<br>
- These values were also <strong>lower</strong> than Binary Classification with Log Regression.</p>
<hr>
</section>
<section id="confusion-matrix-2" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix-2">Confusion Matrix</h3>
<p>The <strong>Confusion Matrix</strong> shows the results of the Random Forest Binary Classification model:<br>
- The model correctly predicted <strong>39 values</strong> of <strong>‘High Voting Rate’</strong> (True Positives).<br>
- The model correctly predicted <strong>34 values</strong> of <strong>‘Low Voting Rate’</strong> (True Negatives).<br>
- The model incorrectly classified <strong>9 values</strong> as <strong>‘High Voting Rate’</strong> when they were actually low (<strong>False Positive</strong>).<br>
- The model incorrectly classified <strong>5 values</strong> as <strong>‘Low Voting Rate’</strong> when they were actually high (<strong>False Negative</strong>).</p>
</section>
</section>
</section>
<section id="binary-method-analysis-and-comparison" class="level1">
<h1>Binary Method Analysis and Comparison</h1>
<div id="cell-36" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the data</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Model'</span>: [<span class="st">'Logistic Regression'</span>, <span class="st">'Decision Tree'</span>, <span class="st">'Random Forest'</span>],</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Class 0 Precision'</span>: [<span class="fl">0.89</span>, <span class="fl">0.76</span>, <span class="fl">0.87</span>],</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Class 0 Recall'</span>: [<span class="fl">0.72</span>, <span class="fl">0.51</span>, <span class="fl">0.79</span>],</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Class 0 F1-Score'</span>: [<span class="fl">0.79</span>, <span class="fl">0.61</span>, <span class="fl">0.83</span>],</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Class 1 Precision'</span>: [<span class="fl">0.77</span>, <span class="fl">0.64</span>, <span class="fl">0.81</span>],</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Class 1 Recall'</span>: [<span class="fl">0.91</span>, <span class="fl">0.84</span>, <span class="fl">0.89</span>],</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Class 1 F1-Score'</span>: [<span class="fl">0.83</span>, <span class="fl">0.73</span>, <span class="fl">0.85</span>],</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Accuracy'</span>: [<span class="fl">0.82</span>, <span class="fl">0.68</span>, <span class="fl">0.84</span>],</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Macro Avg Precision'</span>: [<span class="fl">0.83</span>, <span class="fl">0.70</span>, <span class="fl">0.84</span>],</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Macro Avg Recall'</span>: [<span class="fl">0.82</span>, <span class="fl">0.68</span>, <span class="fl">0.84</span>],</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Macro Avg F1-Score'</span>: [<span class="fl">0.81</span>, <span class="fl">0.67</span>, <span class="fl">0.84</span>]</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the table</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>display(results_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Model</th>
<th data-quarto-table-cell-role="th">Class 0 Precision</th>
<th data-quarto-table-cell-role="th">Class 0 Recall</th>
<th data-quarto-table-cell-role="th">Class 0 F1-Score</th>
<th data-quarto-table-cell-role="th">Class 1 Precision</th>
<th data-quarto-table-cell-role="th">Class 1 Recall</th>
<th data-quarto-table-cell-role="th">Class 1 F1-Score</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Macro Avg Precision</th>
<th data-quarto-table-cell-role="th">Macro Avg Recall</th>
<th data-quarto-table-cell-role="th">Macro Avg F1-Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Logistic Regression</td>
<td>0.89</td>
<td>0.72</td>
<td>0.79</td>
<td>0.77</td>
<td>0.91</td>
<td>0.83</td>
<td>0.82</td>
<td>0.83</td>
<td>0.82</td>
<td>0.81</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Decision Tree</td>
<td>0.76</td>
<td>0.51</td>
<td>0.61</td>
<td>0.64</td>
<td>0.84</td>
<td>0.73</td>
<td>0.68</td>
<td>0.70</td>
<td>0.68</td>
<td>0.67</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Random Forest</td>
<td>0.87</td>
<td>0.79</td>
<td>0.83</td>
<td>0.81</td>
<td>0.89</td>
<td>0.85</td>
<td>0.84</td>
<td>0.84</td>
<td>0.84</td>
<td>0.84</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p><strong>Random Forest</strong> and <strong>Logistic Regression</strong> had the most precise classification, with tradeoffs between them, while <strong>Decision Tree</strong> was the least accurate. Random Forest performed much better than Decision Tree and had similar accuracy to Logistic Regression.</p>
<hr>
<section id="logistic-regression---lower-voting-class" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression---lower-voting-class">Logistic Regression - Lower Voting Class</h3>
<ul>
<li><strong>Precision</strong>: <strong>0.89</strong><br>
</li>
<li><strong>Recall</strong>: <strong>0.72</strong><br>
</li>
<li><strong>F1 Score</strong>: <strong>0.79</strong></li>
</ul>
</section>
<section id="random-forest---lower-voting-class" class="level3">
<h3 class="anchored" data-anchor-id="random-forest---lower-voting-class">Random Forest - Lower Voting Class</h3>
<ul>
<li><strong>Precision</strong>: <strong>0.87</strong><br>
</li>
<li><strong>Recall</strong>: <strong>0.79</strong><br>
</li>
<li><strong>F1 Score</strong>: <strong>0.83</strong></li>
</ul>
<p>Logistic Regression had a <strong>higher Precision score</strong> in classifying “Lower Voting Class,” while Random Forest had a <strong>higher Recall and F1 score</strong>.</p>
<hr>
</section>
<section id="logistic-regression---higher-voting-class" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression---higher-voting-class">Logistic Regression - Higher Voting Class</h3>
<ul>
<li><strong>Precision</strong>: <strong>0.77</strong><br>
</li>
<li><strong>Recall</strong>: <strong>0.91</strong><br>
</li>
<li><strong>F1 Score</strong>: <strong>0.83</strong></li>
</ul>
</section>
<section id="random-forest---higher-voting-class" class="level3">
<h3 class="anchored" data-anchor-id="random-forest---higher-voting-class">Random Forest - Higher Voting Class</h3>
<ul>
<li><strong>Precision</strong>: <strong>0.81</strong><br>
</li>
<li><strong>Recall</strong>: <strong>0.89</strong><br>
</li>
<li><strong>F1 Score</strong>: <strong>0.85</strong></li>
</ul>
<p>Logistic Regression had a <strong>lower Precision</strong> and <strong>F1 score</strong> in classifying “Higher Voting Class” compared to Random Forest, but achieved a <strong>higher Recall score</strong>.</p>
<hr>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li>Random Forest and Logistic Regression show <strong>similar performance</strong> overall, with tradeoffs in Precision, Recall, and F1 scores across both classes.<br>
</li>
<li><strong>Decision Tree</strong> underperformed compared to the other two methods.</li>
</ul>
</section>
</section>
<section id="multiclass-classification-1" class="level1">
<h1>Multiclass Classification</h1>
<section id="target-selection-1" class="level2">
<h2 class="anchored" data-anchor-id="target-selection-1">Target Selection</h2>
<p>I chose my <strong>Binary Classification targets</strong> as:<br>
- <strong>Low Voting Rate</strong><br>
- <strong>Medium Voting Rate</strong><br>
- <strong>High Voting Rate</strong></p>
<p>The data was split into <strong>three quantiles</strong>:<br>
- Districts in the <strong>upper quartile</strong> were labeled as <strong>High Voting Rate</strong>.<br>
- Districts in the <strong>middle quantile</strong> were labeled as <strong>Medium Voting Rate</strong>.<br>
- Districts in the <strong>lower quantile</strong> were labeled as <strong>Low Voting Rate</strong>.</p>
</section>
<section id="log-regression-multiclass-classification" class="level2">
<h2 class="anchored" data-anchor-id="log-regression-multiclass-classification">Log Regression Multiclass Classification</h2>
<div id="cell-38" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>percentiles <span class="op">=</span> processed_df[<span class="st">'voting_rate_estimate'</span>].quantile([<span class="fl">0.33</span>, <span class="fl">0.66</span>])</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new multiclass target column</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_voting_rate(voting_rate):</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> voting_rate <span class="op">&lt;=</span> percentiles[<span class="fl">0.33</span>]:</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'low'</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> voting_rate <span class="op">&lt;=</span> percentiles[<span class="fl">0.66</span>]:</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'median'</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'high'</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>processed_df[<span class="st">'Voting_Rate_Category'</span>] <span class="op">=</span> processed_df[<span class="st">'voting_rate_estimate'</span>].<span class="bu">apply</span>(classify_voting_rate)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co"># print(processed_df['Voting_Rate_Category'].value_counts())</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Define target and features</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>multiclass_target <span class="op">=</span> <span class="st">'Voting_Rate_Category'</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> processed_df.drop(columns<span class="op">=</span>[<span class="st">'Voting_Rate_Category'</span>, <span class="st">'voting_rate_estimate'</span>, <span class="st">'High_Voting_Rate'</span>])</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode target variable into numeric values</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>processed_df[<span class="st">'Voting_Rate_Category_Encoded'</span>] <span class="op">=</span> label_encoder.fit_transform(processed_df[multiclass_target])</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>    features, </span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>    processed_df[<span class="st">'Voting_Rate_Category_Encoded'</span>], </span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb34-39"><a href="#cb34-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-40"><a href="#cb34-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Logistic Regression model with multinomial option</span></span>
<span id="cb34-41"><a href="#cb34-41" aria-hidden="true" tabindex="-1"></a>log_reg_multi <span class="op">=</span> LogisticRegression(multi_class<span class="op">=</span><span class="st">'multinomial'</span>, solver<span class="op">=</span><span class="st">'lbfgs'</span>, max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb34-42"><a href="#cb34-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-43"><a href="#cb34-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb34-44"><a href="#cb34-44" aria-hidden="true" tabindex="-1"></a>log_reg_multi.fit(X_train, y_train)</span>
<span id="cb34-45"><a href="#cb34-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-46"><a href="#cb34-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb34-47"><a href="#cb34-47" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> log_reg_multi.predict(X_train)</span>
<span id="cb34-48"><a href="#cb34-48" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> log_reg_multi.predict(X_test)</span>
<span id="cb34-49"><a href="#cb34-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-50"><a href="#cb34-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb34-51"><a href="#cb34-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Log Regression - Classification Report (Test Data):"</span>)</span>
<span id="cb34-52"><a href="#cb34-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_test, target_names<span class="op">=</span>label_encoder.classes_))</span>
<span id="cb34-53"><a href="#cb34-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-54"><a href="#cb34-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb34-55"><a href="#cb34-55" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred_test)</span>
<span id="cb34-56"><a href="#cb34-56" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb34-57"><a href="#cb34-57" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, xticklabels<span class="op">=</span>label_encoder.classes_, yticklabels<span class="op">=</span>label_encoder.classes_)</span>
<span id="cb34-58"><a href="#cb34-58" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Confusion Matrix"</span>)</span>
<span id="cb34-59"><a href="#cb34-59" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Predicted"</span>)</span>
<span id="cb34-60"><a href="#cb34-60" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Actual"</span>)</span>
<span id="cb34-61"><a href="#cb34-61" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Log Regression - Classification Report (Test Data):
              precision    recall  f1-score   support

        high       0.76      0.81      0.78        31
         low       0.83      0.67      0.74        30
      median       0.47      0.54      0.50        26

    accuracy                           0.68        87
   macro avg       0.69      0.67      0.67        87
weighted avg       0.70      0.68      0.68        87
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/iphone10/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-20-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="log-regression-multiclass-classification-analysis" class="level2">
<h2 class="anchored" data-anchor-id="log-regression-multiclass-classification-analysis">Log Regression Multiclass Classification Analysis</h2>
<div id="cell-40" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>data_log_regression <span class="op">=</span> {</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Class"</span>: [<span class="st">"high"</span>, <span class="st">"low"</span>, <span class="st">"median"</span>, <span class="st">"accuracy"</span>, <span class="st">"macro avg"</span>],</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Precision"</span>: [<span class="fl">0.76</span>, <span class="fl">0.83</span>, <span class="fl">0.47</span>, <span class="va">None</span>, <span class="fl">0.69</span>],</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Recall"</span>: [<span class="fl">0.81</span>, <span class="fl">0.67</span>, <span class="fl">0.54</span>, <span class="va">None</span>, <span class="fl">0.67</span>],</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"F1-Score"</span>: [<span class="fl">0.78</span>, <span class="fl">0.74</span>, <span class="fl">0.50</span>, <span class="fl">0.68</span>, <span class="fl">0.67</span>],</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Support"</span>: [<span class="dv">31</span>, <span class="dv">30</span>, <span class="dv">26</span>, <span class="dv">87</span>, <span class="dv">87</span>]</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the DataFrame for Logistic Regression</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>df_log_regression <span class="op">=</span> pd.DataFrame(data_log_regression)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the DataFrame</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_log_regression)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       Class  Precision  Recall  F1-Score  Support
0       high       0.76    0.81      0.78       31
1        low       0.83    0.67      0.74       30
2     median       0.47    0.54      0.50       26
3   accuracy        NaN     NaN      0.68       87
4  macro avg       0.69    0.67      0.67       87</code></pre>
</div>
</div>
<hr>
<section id="high-voting-rates" class="level3">
<h3 class="anchored" data-anchor-id="high-voting-rates">High Voting Rates</h3>
<p>The accuracy metrics for our model showed that for classification into <strong>High Voting Rates</strong>:<br>
- <strong>Precision</strong>: <strong>0.76</strong> → Of the instances predicted as ‘high,’ 76% were correct.<br>
- <strong>Recall</strong>: <strong>0.81</strong><br>
- <strong>F1 Score</strong>: <strong>0.78</strong></p>
<p>These metrics indicate our model was <strong>pretty accurate</strong> in predicting the <strong>“High Voting Rate”</strong> class.</p>
<hr>
</section>
<section id="low-voting-rates" class="level3">
<h3 class="anchored" data-anchor-id="low-voting-rates">Low Voting Rates</h3>
<p>For classification into <strong>Low Voting Rates</strong>, our model achieved:<br>
- <strong>Precision</strong>: <strong>0.83</strong><br>
- <strong>Recall</strong>: <strong>0.67</strong><br>
- <strong>F1 Score</strong>: <strong>0.74</strong></p>
<p>Similarly to “High Voting Rate,” these metrics indicate our model was <strong>accurate</strong> in predicting the <strong>“Low Voting Rate”</strong> class.</p>
<hr>
</section>
<section id="median-voting-rates" class="level3">
<h3 class="anchored" data-anchor-id="median-voting-rates">Median Voting Rates</h3>
<p>For classification into <strong>Median Voting Rates</strong>, our model had:<br>
- <strong>Precision</strong>: <strong>0.47</strong><br>
- <strong>Recall</strong>: <strong>0.54</strong><br>
- <strong>F1 Score</strong>: <strong>0.50</strong></p>
<p>These metrics indicate our model had a <strong>more difficult time</strong> classifying <strong>“Median Voting Rates.”</strong><br>
- The overall model accuracy was <strong>0.68</strong>, indicating a <strong>moderately accurate model</strong> but with <strong>room for improvement</strong>.</p>
<hr>
</section>
<section id="macro-average-1" class="level3">
<h3 class="anchored" data-anchor-id="macro-average-1">Macro Average</h3>
<p>The <strong>Macro Average</strong> metrics were:<br>
- <strong>Precision</strong>: <strong>0.69</strong><br>
- <strong>Recall</strong>: <strong>0.67</strong><br>
- <strong>F1 Score</strong>: <strong>0.67</strong></p>
<p>These scores indicate that our model performed <strong>pretty well across classes</strong>, but was <strong>dragged down</strong> by the low accuracy scores in classifying <strong>“Median Voting Rates.”</strong></p>
<hr>
</section>
<section id="confusion-matrix-3" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix-3">Confusion Matrix</h3>
<p>The <strong>Confusion Matrix</strong> shows the results of the multiclass classification model:<br>
- Correctly predicted <strong>25 values</strong> of <strong>‘High Voting Rate’</strong> (True Positives).<br>
- Correctly predicted <strong>20 instances</strong> of <strong>‘Low Voting Rate’</strong> (True Positives).<br>
- Correctly predicted <strong>14 instances</strong> of <strong>‘Median Voting Rate.’</strong></p>
<hr>
</section>
<section id="roc-curve-2" class="level3">
<h3 class="anchored" data-anchor-id="roc-curve-2">ROC Curve</h3>
<p>The <strong>ROC Curve</strong> showcases an <strong>AUC score</strong> of <strong>0.87</strong>, indicating an accurate model that distinguishes between <strong>Low</strong> and <strong>High voting rates</strong>.<br>
- The curve rises <strong>steeply</strong>, indicating the model quickly achieves a <strong>high True Positive Rate</strong> with a <strong>low False Positive Rate</strong>.<br>
- Furthermore, the curve is <strong>significantly higher</strong> than the diagonal (baseline) curve, showing that the model is <strong>better than a random classifier</strong>.</p>
</section>
</section>
<section id="decision-tree-multiclass-classification" class="level2">
<h2 class="anchored" data-anchor-id="decision-tree-multiclass-classification">Decision Tree Multiclass Classification</h2>
<div id="cell-42" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Decision Tree Classifier</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>dt_clf_multi <span class="op">=</span> DecisionTreeClassifier(</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    criterion<span class="op">=</span><span class="st">'entropy'</span>,    <span class="co"># Use 'entropy' to measure information gain</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">5</span>,            <span class="co"># Limit depth to prevent overfitting</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">10</span>,   <span class="co"># Minimum samples to split a node</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">5</span>,     <span class="co"># Minimum samples in each leaf node</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>         <span class="co"># For reproducibility</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>dt_clf_multi.fit(X_train, y_train)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> dt_clf_multi.predict(X_train)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> dt_clf_multi.predict(X_test)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Decision Tree - Classification Report (Test Data):"</span>)</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_test, target_names<span class="op">=</span>label_encoder.classes_))</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred_test)</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, xticklabels<span class="op">=</span>label_encoder.classes_, yticklabels<span class="op">=</span>label_encoder.classes_)</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Decision Tree - Confusion Matrix"</span>)</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Predicted"</span>)</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Actual"</span>)</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Decision Tree - Classification Report (Test Data):
              precision    recall  f1-score   support

        high       0.64      0.68      0.66        31
         low       0.79      0.50      0.61        30
      median       0.37      0.50      0.43        26

    accuracy                           0.56        87
   macro avg       0.60      0.56      0.56        87
weighted avg       0.61      0.56      0.57        87
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-22-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="decision-tree-multiclass-classification-analysis" class="level2">
<h2 class="anchored" data-anchor-id="decision-tree-multiclass-classification-analysis">Decision Tree Multiclass Classification Analysis</h2>
<div id="cell-44" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>data_decision_tree <span class="op">=</span> {</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Class"</span>: [<span class="st">"high"</span>, <span class="st">"low"</span>, <span class="st">"median"</span>, <span class="st">"accuracy"</span>, <span class="st">"macro avg"</span>],</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Precision"</span>: [<span class="fl">0.64</span>, <span class="fl">0.79</span>, <span class="fl">0.37</span>, <span class="va">None</span>, <span class="fl">0.60</span>],</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Recall"</span>: [<span class="fl">0.68</span>, <span class="fl">0.50</span>, <span class="fl">0.50</span>, <span class="va">None</span>, <span class="fl">0.56</span>],</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"F1-Score"</span>: [<span class="fl">0.66</span>, <span class="fl">0.61</span>, <span class="fl">0.43</span>, <span class="fl">0.56</span>, <span class="fl">0.56</span>],</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Support"</span>: [<span class="dv">31</span>, <span class="dv">30</span>, <span class="dv">26</span>, <span class="dv">87</span>, <span class="dv">87</span>]</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the DataFrame for Decision Tree</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>df_decision_tree <span class="op">=</span> pd.DataFrame(data_decision_tree)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_decision_tree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       Class  Precision  Recall  F1-Score  Support
0       high       0.64    0.68      0.66       31
1        low       0.79    0.50      0.61       30
2     median       0.37    0.50      0.43       26
3   accuracy        NaN     NaN      0.56       87
4  macro avg       0.60    0.56      0.56       87</code></pre>
</div>
</div>
<section id="high-voting-rates-1" class="level3">
<h3 class="anchored" data-anchor-id="high-voting-rates-1">High Voting Rates</h3>
<p>The accuracy metrics for our model showed that for classification into <strong>High Voting Rates</strong>:<br>
- <strong>Precision</strong>: <strong>0.64</strong> → Of the instances predicted as ‘high,’ 64% were correct.<br>
- <strong>Recall</strong>: <strong>0.68</strong><br>
- <strong>F1 Score</strong>: <strong>0.66</strong></p>
<p>These metrics indicate our model was <strong>moderately accurate</strong> in predicting the <strong>“High Voting Rate”</strong> class.</p>
<hr>
</section>
<section id="low-voting-rates-1" class="level3">
<h3 class="anchored" data-anchor-id="low-voting-rates-1">Low Voting Rates</h3>
<p>For classification into <strong>Low Voting Rates</strong>, our model achieved:<br>
- <strong>Precision</strong>: <strong>0.79</strong><br>
- <strong>Recall</strong>: <strong>0.50</strong><br>
- <strong>F1 Score</strong>: <strong>0.71</strong></p>
<p>Similarly to “High Voting Rate,” these metrics indicate our model was <strong>accurate</strong> in predicting the <strong>“Low Voting Rate”</strong> class.</p>
<hr>
</section>
<section id="median-voting-rates-1" class="level3">
<h3 class="anchored" data-anchor-id="median-voting-rates-1">Median Voting Rates</h3>
<p>For classification into <strong>Median Voting Rates</strong>, our model only achieved:<br>
- <strong>Precision</strong>: <strong>0.37</strong><br>
- <strong>Recall</strong>: <strong>0.50</strong><br>
- <strong>F1 Score</strong>: <strong>0.61</strong></p>
<p>These metrics indicate our model had a <strong>difficult time</strong> classifying <strong>“Median Voting Rates.”</strong></p>
<hr>
</section>
<section id="accuracy-1" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-1">Accuracy</h3>
<p>The model had an <strong>accuracy</strong> of <strong>0.56</strong>, indicating a <strong>moderately accurate model</strong> but with <strong>room for improvement</strong>.</p>
<hr>
</section>
<section id="macro-average-2" class="level3">
<h3 class="anchored" data-anchor-id="macro-average-2">Macro Average</h3>
<p>The <strong>Macro Average</strong> metrics were:<br>
- <strong>Precision</strong>: <strong>0.60</strong><br>
- <strong>Recall</strong>: <strong>0.56</strong><br>
- <strong>F1 Score</strong>: <strong>0.56</strong></p>
<p>These scores indicate that our model performed <strong>a little better than average</strong> in accuracy metrics across classes. However, similar to earlier, performance was <strong>dragged down</strong> by the <strong>low accuracy scores</strong> in classifying <strong>“Median Voting Rates.”</strong></p>
<hr>
</section>
<section id="confusion-matrix-4" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix-4">Confusion Matrix</h3>
<p>The <strong>Confusion Matrix</strong> shows the results of the multiclass classification model:<br>
- Correctly predicted <strong>21 values</strong> of <strong>‘High Voting Rate’</strong> (True Positives).<br>
- Correctly predicted <strong>15 instances</strong> of <strong>‘Low Voting Rate’</strong> (True Positives).<br>
- Correctly predicted <strong>13 instances</strong> of <strong>‘Median Voting Rate.’</strong></p>
</section>
</section>
<section id="decision-tree-2" class="level2">
<h2 class="anchored" data-anchor-id="decision-tree-2">Decision Tree</h2>
<div id="cell-46" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> plot_tree</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>plot_tree(</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    dt_clf_multi, </span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    feature_names<span class="op">=</span>X_train.columns, </span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    class_names<span class="op">=</span>label_encoder.classes_, </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    filled<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    rounded<span class="op">=</span><span class="va">True</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="random-forest-multiclass-classification" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-multiclass-classification">Random Forest Multiclass Classification</h2>
<div id="cell-48" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Random Forest Classifier</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>rf_clf_multi <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,       <span class="co"># Number of trees</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">10</span>,           <span class="co"># Maximum depth of trees</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">10</span>,   <span class="co"># Minimum samples to split a node</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">5</span>,     <span class="co"># Minimum samples in each leaf node</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>         <span class="co"># For reproducibility</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>rf_clf_multi.fit(X_train, y_train)</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> rf_clf_multi.predict(X_train)</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> rf_clf_multi.predict(X_test)</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest - Classification Report (Test Data):"</span>)</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_test, target_names<span class="op">=</span>label_encoder.classes_))</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred_test)</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, xticklabels<span class="op">=</span>label_encoder.classes_, yticklabels<span class="op">=</span>label_encoder.classes_)</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Random Forest - Confusion Matrix"</span>)</span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Predicted"</span>)</span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Actual"</span>)</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest - Classification Report (Test Data):
              precision    recall  f1-score   support

        high       0.68      0.81      0.74        31
         low       0.82      0.60      0.69        30
      median       0.39      0.42      0.41        26

    accuracy                           0.62        87
   macro avg       0.63      0.61      0.61        87
weighted avg       0.64      0.62      0.62        87
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-25-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="random-forest-multiclass-classification-feature-importance" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-multiclass-classification-feature-importance">Random Forest Multiclass Classification Feature Importance</h2>
<div id="cell-50" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Access feature importance</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>feature_importances <span class="op">=</span> rf_clf_multi.feature_importances_</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine with feature names</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: feature_importances</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>}).sort_values(by<span class="op">=</span><span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot feature importance</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>plt.barh(importance_df[<span class="st">'Feature'</span>], importance_df[<span class="st">'Importance'</span>])</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature Importance"</span>)</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature"</span>)</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Random Forest Feature Importance"</span>)</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()  <span class="co"># Reverse order for better readability</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Display top predictors</span></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(importance_df.head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-26-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                        Feature  Importance
8    Bachelors_Degree_or_Higher    0.143876
5           Below_Poverty_Level    0.131789
10     Households_with_Internet    0.114182
9     Households_with_Computers    0.092793
6   Log_Median_Household_Income    0.089420
13                   Median_Age    0.077783
4                      Veterans    0.048003
7          High_School_Graduate    0.045844
2                         White    0.043331
3                     Log_Asian    0.042718</code></pre>
</div>
</div>
<p>For <strong>Multiclass Classification</strong>, the Random Forest deemed Bachelors Degree or Higher, Poverty Level, Internet Access, Households with Computers, Median Household Income as the most defining features in making splits.</p>
</section>
<section id="random-forest-multiclass-classification-analysis" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-multiclass-classification-analysis">Random Forest Multiclass Classification Analysis</h2>
<div id="cell-52" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Data for the classification report</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>random_forest_metrics <span class="op">=</span> {</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Class"</span>: [<span class="st">"high"</span>, <span class="st">"low"</span>, <span class="st">"median"</span>, <span class="st">"accuracy"</span>, <span class="st">"macro avg"</span>],</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Precision"</span>: [<span class="fl">0.68</span>, <span class="fl">0.82</span>, <span class="fl">0.39</span>, <span class="va">None</span>, <span class="fl">0.63</span>],</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Recall"</span>: [<span class="fl">0.81</span>, <span class="fl">0.60</span>, <span class="fl">0.42</span>, <span class="va">None</span>, <span class="fl">0.61</span>],</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"F1-Score"</span>: [<span class="fl">0.74</span>, <span class="fl">0.69</span>, <span class="fl">0.41</span>, <span class="fl">0.62</span>, <span class="fl">0.61</span>],</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Support"</span>: [<span class="dv">31</span>, <span class="dv">30</span>, <span class="dv">26</span>, <span class="dv">87</span>, <span class="dv">87</span>]</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>random_forest_multi_df <span class="op">=</span> pd.DataFrame(random_forest_metrics)</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(random_forest_multi_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       Class  Precision  Recall  F1-Score  Support
0       high       0.68    0.81      0.74       31
1        low       0.82    0.60      0.69       30
2     median       0.39    0.42      0.41       26
3   accuracy        NaN     NaN      0.62       87
4  macro avg       0.63    0.61      0.61       87</code></pre>
</div>
</div>
<hr>
<section id="high-voting-rates-2" class="level3">
<h3 class="anchored" data-anchor-id="high-voting-rates-2">High Voting Rates</h3>
<p>The accuracy metrics for our model showed that for classification into <strong>High Voting Rates</strong>:<br>
- <strong>Precision</strong>: <strong>0.68</strong> → Of the instances predicted as ‘high,’ 68% were correct.<br>
- <strong>Recall</strong>: <strong>0.81</strong><br>
- <strong>F1 Score</strong>: <strong>0.74</strong></p>
<p>This indicates our model was <strong>reasonably accurate</strong> in predicting the <strong>“High Voting Rate”</strong> class.</p>
<hr>
</section>
<section id="low-voting-rates-2" class="level3">
<h3 class="anchored" data-anchor-id="low-voting-rates-2">Low Voting Rates</h3>
<p>For classification into <strong>Low Voting Rates</strong>, our model achieved:<br>
- <strong>Precision</strong>: <strong>0.82</strong><br>
- <strong>Recall</strong>: <strong>0.60</strong><br>
- <strong>F1 Score</strong>: <strong>0.69</strong></p>
<p>These metrics suggest the model performed <strong>well</strong> in predicting the <strong>“Low Voting Rate”</strong> class, but with slightly lower recall.</p>
<hr>
</section>
<section id="median-voting-rates-2" class="level3">
<h3 class="anchored" data-anchor-id="median-voting-rates-2">Median Voting Rates</h3>
<p>For classification into <strong>Median Voting Rates</strong>, our model had:<br>
- <strong>Precision</strong>: <strong>0.39</strong><br>
- <strong>Recall</strong>: <strong>0.42</strong><br>
- <strong>F1 Score</strong>: <strong>0.41</strong></p>
<p>These scores indicate that the model had a <strong>difficult time</strong> classifying <strong>“Median Voting Rates”</strong>, which affected overall performance.</p>
<hr>
</section>
<section id="accuracy-2" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-2">Accuracy</h3>
<p>The overall model accuracy was <strong>0.62</strong>, indicating a <strong>moderately accurate model</strong> but with <strong>room for improvement</strong>, particularly for the <strong>Median Voting Rate</strong> class.</p>
<hr>
</section>
<section id="macro-average-3" class="level3">
<h3 class="anchored" data-anchor-id="macro-average-3">Macro Average</h3>
<p>The <strong>Macro Average</strong> metrics were:<br>
- <strong>Precision</strong>: <strong>0.63</strong><br>
- <strong>Recall</strong>: <strong>0.61</strong><br>
- <strong>F1 Score</strong>: <strong>0.61</strong></p>
<p>These scores show that the model performed <strong>better overall</strong> for High and Low classes, but struggled with the <strong>Median class</strong>, lowering the average scores.</p>
<hr>
</section>
<section id="confusion-matrix-5" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix-5">Confusion Matrix</h3>
<p>The <strong>Confusion Matrix</strong> shows the results of the multiclass classification model:<br>
- Correctly predicted <strong>25 values</strong> of <strong>‘High Voting Rate’</strong> (True Positives).<br>
- Correctly predicted <strong>18 instances</strong> of <strong>‘Low Voting Rate’</strong> (True Positives).<br>
- Correctly predicted <strong>11 instances</strong> of <strong>‘Median Voting Rate.’</strong></p>
<hr>
</section>
</section>
<section id="multiclass-classification-analysis-and-comparison" class="level2">
<h2 class="anchored" data-anchor-id="multiclass-classification-analysis-and-comparison">Multiclass Classification Analysis and Comparison</h2>
<div id="cell-54" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the data</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Model'</span>: [<span class="st">'Logistic Regression'</span>, <span class="st">'Decision Tree'</span>, <span class="st">'Random Forest'</span>],</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'High Precision'</span>: [<span class="fl">0.76</span>, <span class="fl">0.64</span>, <span class="fl">0.68</span>],</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'High Recall'</span>: [<span class="fl">0.81</span>, <span class="fl">0.68</span>, <span class="fl">0.81</span>],</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'High F1-Score'</span>: [<span class="fl">0.78</span>, <span class="fl">0.66</span>, <span class="fl">0.74</span>],</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Low Precision'</span>: [<span class="fl">0.83</span>, <span class="fl">0.79</span>, <span class="fl">0.82</span>],</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Low Recall'</span>: [<span class="fl">0.67</span>, <span class="fl">0.50</span>, <span class="fl">0.60</span>],</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Low F1-Score'</span>: [<span class="fl">0.74</span>, <span class="fl">0.61</span>, <span class="fl">0.69</span>],</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Median Precision'</span>: [<span class="fl">0.47</span>, <span class="fl">0.37</span>, <span class="fl">0.39</span>],</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Median Recall'</span>: [<span class="fl">0.54</span>, <span class="fl">0.50</span>, <span class="fl">0.42</span>],</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Median F1-Score'</span>: [<span class="fl">0.50</span>, <span class="fl">0.43</span>, <span class="fl">0.41</span>],</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Accuracy'</span>: [<span class="fl">0.68</span>, <span class="fl">0.56</span>, <span class="fl">0.62</span>],</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Macro Avg Precision'</span>: [<span class="fl">0.69</span>, <span class="fl">0.60</span>, <span class="fl">0.63</span>],</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Macro Avg Recall'</span>: [<span class="fl">0.67</span>, <span class="fl">0.56</span>, <span class="fl">0.61</span>],</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Macro Avg F1-Score'</span>: [<span class="fl">0.67</span>, <span class="fl">0.56</span>, <span class="fl">0.61</span>]</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame</span></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Display table in a nice format</span></span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a>display(results_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Model</th>
<th data-quarto-table-cell-role="th">High Precision</th>
<th data-quarto-table-cell-role="th">High Recall</th>
<th data-quarto-table-cell-role="th">High F1-Score</th>
<th data-quarto-table-cell-role="th">Low Precision</th>
<th data-quarto-table-cell-role="th">Low Recall</th>
<th data-quarto-table-cell-role="th">Low F1-Score</th>
<th data-quarto-table-cell-role="th">Median Precision</th>
<th data-quarto-table-cell-role="th">Median Recall</th>
<th data-quarto-table-cell-role="th">Median F1-Score</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Macro Avg Precision</th>
<th data-quarto-table-cell-role="th">Macro Avg Recall</th>
<th data-quarto-table-cell-role="th">Macro Avg F1-Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Logistic Regression</td>
<td>0.76</td>
<td>0.81</td>
<td>0.78</td>
<td>0.83</td>
<td>0.67</td>
<td>0.74</td>
<td>0.47</td>
<td>0.54</td>
<td>0.50</td>
<td>0.68</td>
<td>0.69</td>
<td>0.67</td>
<td>0.67</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Decision Tree</td>
<td>0.64</td>
<td>0.68</td>
<td>0.66</td>
<td>0.79</td>
<td>0.50</td>
<td>0.61</td>
<td>0.37</td>
<td>0.50</td>
<td>0.43</td>
<td>0.56</td>
<td>0.60</td>
<td>0.56</td>
<td>0.56</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Random Forest</td>
<td>0.68</td>
<td>0.81</td>
<td>0.74</td>
<td>0.82</td>
<td>0.60</td>
<td>0.69</td>
<td>0.39</td>
<td>0.42</td>
<td>0.41</td>
<td>0.62</td>
<td>0.63</td>
<td>0.61</td>
<td>0.61</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="conclusion-1" class="level1">
<h1>Conclusion</h1>
<p>Utilizing <strong>Supervised Learning</strong> enabled us to predict <strong>voting rates</strong> and classify districts into different classes effectively.</p>
<hr>
<section id="supervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h2>
<section id="regression-3" class="level3">
<h3 class="anchored" data-anchor-id="regression-3">Regression</h3>
<ul>
<li>The model predicted <strong>voting rate estimates</strong> with <strong>moderate accuracy</strong>.<br>
</li>
<li><strong>RMSE</strong> and <strong>R² values</strong> indicated the model’s ability to minimize errors and explain trends in the data.</li>
</ul>
</section>
<section id="binary-classification-2" class="level3">
<h3 class="anchored" data-anchor-id="binary-classification-2">Binary Classification</h3>
<ul>
<li><strong>Logistic Regression</strong> and <strong>Random Forest</strong> outperformed <strong>Decision Tree</strong> in distinguishing between <strong>High</strong> and <strong>Low Voting Rates</strong>.<br>
</li>
<li>Tradeoffs were observed between <strong>Precision</strong>, <strong>Recall</strong>, and <strong>F1 scores</strong> across the models.</li>
</ul>
</section>
<section id="multiclass-classification-2" class="level3">
<h3 class="anchored" data-anchor-id="multiclass-classification-2">Multiclass Classification</h3>
<ul>
<li>All models struggled to classify <strong>Median Voting Rates</strong>, which significantly impacted overall performance.<br>
</li>
<li><strong>Logistic Regression</strong> performed the best with a <strong>Macro Average Precision</strong> of <strong>0.69</strong>, followed by <strong>Random Forest</strong> with <strong>0.63</strong>.</li>
</ul>
<hr>
</section>
</section>
<section id="key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h2>
<ul>
<li><strong>Logistic Regression</strong>
<ul>
<li>Had the <strong>highest accuracy</strong> for both Regression and Classification.<br>
</li>
<li>Likely due to its <strong>simplicity</strong> and <strong>interpretability</strong>.</li>
</ul></li>
<li><strong>Decision Tree</strong>
<ul>
<li>Achieved the <strong>least accurate metrics</strong> for Regression and Classification.<br>
</li>
<li>This was likely due to <strong>overfitting</strong>, a common challenge with Decision Trees.</li>
</ul></li>
<li><strong>Random Forest</strong>
<ul>
<li>Provided <strong>accurate results</strong>, outperforming Decision Tree.<br>
</li>
<li>This was likely due to <strong>reduced overfitting</strong> through its ensemble approach.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<ul>
<li>The model needs further <strong>fine-tuning</strong> to increase accuracy.
<ul>
<li>For instance, <strong>Multiclass Classification</strong> struggled with the <strong>Median class</strong>, scoring poorly.<br>
</li>
<li>Introducing methods like <strong>feature engineering</strong> or <strong>hyperparameter optimization</strong> may improve performance.</li>
</ul></li>
<li>Once refined, these models can be utilized for <strong>real-world applications</strong>, providing policymakers with <strong>informative data</strong> on <strong>voting rates</strong> and <strong>patterns</strong> to guide better decision-making.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/pinghill87\.github\.io\/portfoliotest\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>