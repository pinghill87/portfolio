<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Soong Ping Hill – Unsupervised Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Soong Ping Hill</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../../projects/DS5000/index.html">
 <span class="dropdown-text">Voting Behavior Prediction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projects/DS5100/index.html">
 <span class="dropdown-text">Airbnb Pricing Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projects/Scholarship/index.html">
 <span class="dropdown-text">Humanitarian Security Research</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../projects/DS5000/data-collection/main.html">Technical details</a></li><li class="breadcrumb-item"><a href="../../../projects/DS5000/unsupervised-learning/main.html">Unsupervised Learning</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/report.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Report</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Technical details</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/data-collection/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Collection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/data-cleaning/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Cleaning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/eda/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exploratory Data Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/unsupervised-learning/main.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Unsupervised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/DS5000/supervised-learning/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Supervised Learning</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#dimensionality-reduction" id="toc-dimensionality-reduction" class="nav-link" data-scroll-target="#dimensionality-reduction">Dimensionality Reduction</a>
  <ul class="collapse">
  <li><a href="#pca" id="toc-pca" class="nav-link" data-scroll-target="#pca">PCA</a></li>
  <li><a href="#t-sne" id="toc-t-sne" class="nav-link" data-scroll-target="#t-sne">T-SNE</a></li>
  </ul></li>
  <li><a href="#effectiveness-of-pca-and-t-sne-in-preserving-data-structure" id="toc-effectiveness-of-pca-and-t-sne-in-preserving-data-structure" class="nav-link" data-scroll-target="#effectiveness-of-pca-and-t-sne-in-preserving-data-structure">Effectiveness of PCA and t-SNE in preserving data structure</a>
  <ul class="collapse">
  <li><a href="#pca-1" id="toc-pca-1" class="nav-link" data-scroll-target="#pca-1">PCA</a></li>
  <li><a href="#t-sne-1" id="toc-t-sne-1" class="nav-link" data-scroll-target="#t-sne-1">t-SNE</a></li>
  </ul></li>
  <li><a href="#vizualizaion-with-pca-and-t-sne" id="toc-vizualizaion-with-pca-and-t-sne" class="nav-link" data-scroll-target="#vizualizaion-with-pca-and-t-sne">Vizualizaion with PCA and t-SNE</a>
  <ul class="collapse">
  <li><a href="#pca-2" id="toc-pca-2" class="nav-link" data-scroll-target="#pca-2">PCA</a></li>
  <li><a href="#t-sne-2" id="toc-t-sne-2" class="nav-link" data-scroll-target="#t-sne-2">t-SNE</a></li>
  </ul></li>
  <li><a href="#comparing-pca-and-t-sne-tradeoffs" id="toc-comparing-pca-and-t-sne-tradeoffs" class="nav-link" data-scroll-target="#comparing-pca-and-t-sne-tradeoffs">Comparing PCA and t-SNE tradeoffs</a>
  <ul class="collapse">
  <li><a href="#pca-3" id="toc-pca-3" class="nav-link" data-scroll-target="#pca-3">PCA</a></li>
  <li><a href="#t-sne-3" id="toc-t-sne-3" class="nav-link" data-scroll-target="#t-sne-3">t-SNE</a></li>
  </ul></li>
  <li><a href="#pca-vs-t-sne-results-analysis" id="toc-pca-vs-t-sne-results-analysis" class="nav-link" data-scroll-target="#pca-vs-t-sne-results-analysis">PCA vs t-SNE Results Analysis</a>
  <ul class="collapse">
  <li><a href="#pca-results" id="toc-pca-results" class="nav-link" data-scroll-target="#pca-results">PCA Results</a></li>
  <li><a href="#t-sne-results" id="toc-t-sne-results" class="nav-link" data-scroll-target="#t-sne-results">t-SNE Results</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  <li><a href="#clustering" id="toc-clustering" class="nav-link" data-scroll-target="#clustering">Clustering</a>
  <ul class="collapse">
  <li><a href="#k-means" id="toc-k-means" class="nav-link" data-scroll-target="#k-means">K-means</a></li>
  <li><a href="#dbscan" id="toc-dbscan" class="nav-link" data-scroll-target="#dbscan">DBSCAN</a></li>
  <li><a href="#hierarchical-clustering" id="toc-hierarchical-clustering" class="nav-link" data-scroll-target="#hierarchical-clustering">Hierarchical Clustering</a></li>
  <li><a href="#hyperparameter-optimization" id="toc-hyperparameter-optimization" class="nav-link" data-scroll-target="#hyperparameter-optimization">Hyperparameter Optimization</a>
  <ul class="collapse">
  <li><a href="#using-silhouette-score-for-optimization" id="toc-using-silhouette-score-for-optimization" class="nav-link" data-scroll-target="#using-silhouette-score-for-optimization">Using Silhouette Score for Optimization</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#k-means-1" id="toc-k-means-1" class="nav-link" data-scroll-target="#k-means-1">K-Means</a></li>
  <li><a href="#dbscan-1" id="toc-dbscan-1" class="nav-link" data-scroll-target="#dbscan-1">DBSCAN</a>
  <ul class="collapse">
  <li><a href="#dbscan-with-varied-eps" id="toc-dbscan-with-varied-eps" class="nav-link" data-scroll-target="#dbscan-with-varied-eps">DBSCAN With Varied EPS</a></li>
  <li><a href="#dbscan-plotted-with-voting-rate-and-key-features" id="toc-dbscan-plotted-with-voting-rate-and-key-features" class="nav-link" data-scroll-target="#dbscan-plotted-with-voting-rate-and-key-features">DBSCAN Plotted with Voting Rate and Key Features</a></li>
  </ul></li>
  <li><a href="#hierarchical-clustering-1" id="toc-hierarchical-clustering-1" class="nav-link" data-scroll-target="#hierarchical-clustering-1">Hierarchical Clustering</a></li>
  <li><a href="#comparing-the-results" id="toc-comparing-the-results" class="nav-link" data-scroll-target="#comparing-the-results"><strong>Comparing the Results</strong></a>
  <ul class="collapse">
  <li><a href="#k-means-clustering" id="toc-k-means-clustering" class="nav-link" data-scroll-target="#k-means-clustering"><strong>K-Means Clustering</strong></a></li>
  <li><a href="#dbscan-clustering" id="toc-dbscan-clustering" class="nav-link" data-scroll-target="#dbscan-clustering"><strong>DBSCAN Clustering</strong></a></li>
  <li><a href="#hierarchical-clustering-2" id="toc-hierarchical-clustering-2" class="nav-link" data-scroll-target="#hierarchical-clustering-2"><strong>Hierarchical Clustering</strong></a></li>
  <li><a href="#best-algorithm" id="toc-best-algorithm" class="nav-link" data-scroll-target="#best-algorithm"><strong>Best Algorithm</strong></a></li>
  <li><a href="#real-world-impact" id="toc-real-world-impact" class="nav-link" data-scroll-target="#real-world-impact"><strong>Real World Impact</strong></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../projects/DS5000/data-collection/main.html">Technical details</a></li><li class="breadcrumb-item"><a href="../../../projects/DS5000/unsupervised-learning/main.html">Unsupervised Learning</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Unsupervised Learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- After digesting the instructions, you can delete this cell, these are assignment instructions and do not need to be included in your final submission.  -->
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Unsupervised Learning is a type of machine learning that analyzes data in the absence of labels. Unsupervised learning involves clustering and dimensionality reduction, both used to discover patterns and insights in the data not seen before.</p>
</section>
<section id="dimensionality-reduction" class="level1">
<h1>Dimensionality Reduction</h1>
<p>Dimensionality Reduction refers to the method of reducing the amount of features in a dataset. There are many issues when visualizing data with multiple features, as it is difficult to visualize the amount of dimensions in an understandable way. Dimensional Reduction reduces the number of features down, while taking into account the most amount of variance.</p>
<section id="pca" class="level2">
<h2 class="anchored" data-anchor-id="pca">PCA</h2>
<p>Principal Component Analysis, known as PCA is the most commonly used dimensionality reduction technique, and involves transforming the data points into new calculated variables named “Principal Components”. Each component is comprised of linear combinations of the original feature, and captures the direction of maximum variance. When plotting the top two Principal Components, we essentially are able to use two features that take into account the majority of explained variance for the dataset.</p>
<div id="cell-4" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>merged_standard_log_df <span class="op">=</span> pd.read_csv(<span class="st">'../../data/processed-data/merged_standard_log.csv'</span>) </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>merged_standard_log_df[<span class="st">'Congressional_District'</span>] <span class="op">=</span> merged_standard_log_df[<span class="st">'Congressional_District'</span>].astype(<span class="bu">str</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Column Types:"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(merged_standard_log_df.dtypes)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>numerical_columns <span class="op">=</span> merged_standard_log_df.select_dtypes(include<span class="op">=</span>[<span class="st">'float64'</span>, <span class="st">'int64'</span>]).columns</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA()</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit and transform with PCA</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>numerical_data <span class="op">=</span> merged_standard_log_df[numerical_columns]</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>pca_result <span class="op">=</span> pca.fit_transform(numerical_data)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot explained variance ratio</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(pca.explained_variance_ratio_) <span class="op">+</span> <span class="dv">1</span>), pca.explained_variance_ratio_, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Explained Variance by Principal Components'</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Principal Component'</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Explained Variance Ratio'</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize first two components</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>plt.scatter(pca_result[:, <span class="dv">0</span>], pca_result[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA: First Two Principal Components'</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Column Types:
District_Name                                object
Total_Population                            float64
Log_African_American                        float64
White                                       float64
Log_Asian                                   float64
Veterans                                    float64
Nonveterans                                 float64
Below_Poverty_Level                         float64
Log_Median_Household_Income                 float64
High_School_Graduate                        float64
Bachelors_Degree_or_Higher                  float64
Households_with_Computers                   float64
Households_with_Internet                    float64
Log_American_Indian_and_Alaska_Native       float64
Log_Native_Hawaiian_and_Pacific_Islander    float64
Median_Age                                  float64
state                                        object
Congressional_District                       object
state_abbreviation                           object
votes_cast                                  float64
citizen_voting_age_population_estimate      float64
voting_rate_estimate                        float64
dtype: object</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-2-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-2-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-5" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>loadings <span class="op">=</span> pd.DataFrame(pca.components_, columns<span class="op">=</span>numerical_columns, index<span class="op">=</span>[<span class="ss">f'PC</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(pca.components_))])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(loadings.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     Total_Population  Log_African_American     White  Log_Asian  Veterans  \
PC1          0.221261             -0.077622  0.180383   0.135435  0.129197   
PC2          0.003581              0.071083 -0.307170   0.436838 -0.371627   
PC3          0.454383              0.309031 -0.118751   0.053967  0.050890   
PC4          0.078886             -0.503244  0.247943   0.003214  0.166664   
PC5         -0.202893              0.410686 -0.420307   0.062545  0.413256   

     Nonveterans  Below_Poverty_Level  Log_Median_Household_Income  \
PC1     0.250760            -0.247778                     0.248968   
PC2     0.105086            -0.097141                     0.315748   
PC3     0.358875             0.409264                    -0.219878   
PC4    -0.119718            -0.047839                     0.030063   
PC5    -0.340224            -0.057707                    -0.032332   

     High_School_Graduate  Bachelors_Degree_or_Higher  \
PC1             -0.099454                    0.325701   
PC2             -0.430129                    0.256663   
PC3              0.073896                   -0.005068   
PC4             -0.130613                   -0.091365   
PC5             -0.075391                   -0.029165   

     Households_with_Computers  Households_with_Internet  \
PC1                   0.343100                  0.367542   
PC2                  -0.095719                 -0.035598   
PC3                   0.198160                  0.121688   
PC4                  -0.076882                 -0.068557   
PC5                   0.035117                  0.040119   

     Log_American_Indian_and_Alaska_Native  \
PC1                              -0.000999   
PC2                               0.001622   
PC3                               0.206009   
PC4                               0.588957   
PC5                               0.005147   

     Log_Native_Hawaiian_and_Pacific_Islander  Median_Age  votes_cast  \
PC1                                  0.028738    0.133872    0.355285   
PC2                                  0.133370   -0.253671   -0.132977   
PC3                                  0.146122   -0.326118   -0.096013   
PC4                                  0.466289   -0.168528   -0.031685   
PC5                                  0.504108    0.093730    0.124426   

     citizen_voting_age_population_estimate  voting_rate_estimate  
PC1                                0.279135              0.315462  
PC2                               -0.300544              0.002436  
PC3                                0.171596             -0.255788  
PC4                               -0.060010             -0.020372  
PC5                                0.127527              0.120975  </code></pre>
</div>
</div>
<p>Feature loadings are analyzed to understand the driving factors behind each Principal Component. Each feature loading is the weight of the original variables contribution in the PCA.</p>
<p>This revealed that PC1 was positively correlated with Total Population, Median Household Income, Nonveterans, Bachelors Degree or Higher, and slightly correlated with White. PC1 was also negatively correlated with Below Poverty Level and slightly negatively correlated with High School Graduate. This indicates that PC1s with higher values are those with a higher total population, higher median household income, more degree of whites etc.</p>
<p>PC2 was positively correlated with Asian, Median Household Income and Bachelors Degree or Higher, while negatively correlated with Veterans, White, and High School Graduate. PC1’s components of higher education, income, and population size link it to higher voting rate, while PC2’s components of Asian, Veterans, and White reflect a more Cultural and Socioeconomic Difference rather than voting.</p>
<div id="cell-7" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(pca_result[:, <span class="dv">0</span>], pca_result[:, <span class="dv">1</span>], c<span class="op">=</span>merged_standard_log_df[<span class="st">'voting_rate_estimate'</span>], cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA: First Two Principal Components'</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.colorbar(label<span class="op">=</span><span class="st">'Voting Rate Estimate'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>When we color our plot by voting rate estimate, however, we can see that PC1 is correlated with a higher voting rate. Values with a higher voting rate are clustered in the positive PC1 direction. PC2 does not seem to have an effect on voting rate estimate. ### PCA Correlation</p>
<div id="cell-9" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>pc_df <span class="op">=</span> pd.DataFrame(pca_result, columns<span class="op">=</span>[<span class="ss">f'PC</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(pca_result.shape[<span class="dv">1</span>])])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>pc_df[<span class="st">'voting_rate_estimate'</span>] <span class="op">=</span> merged_standard_log_df[<span class="st">'voting_rate_estimate'</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>correlations <span class="op">=</span> pc_df.corr()</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(correlations[<span class="st">'voting_rate_estimate'</span>].sort_values(ascending<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>voting_rate_estimate    1.000000
PC1                     0.789800
PC9                     0.287184
PC5                     0.118478
PC8                     0.116832
PC11                    0.078606
PC7                     0.049434
PC15                    0.013838
PC14                    0.011249
PC16                    0.008906
PC17                    0.005504
PC2                     0.004660
PC10                   -0.004199
PC4                    -0.026708
PC18                   -0.031082
PC13                   -0.041294
PC12                   -0.091670
PC6                    -0.292916
PC3                    -0.399221
Name: voting_rate_estimate, dtype: float64</code></pre>
</div>
</div>
<p>Analyzing Voting Rate correlalation, we see that that PC1 is positively correlated with voting rate, achieving a score of 0.789, while PC2 only had a score of 0.0046.</p>
</section>
<section id="t-sne" class="level2">
<h2 class="anchored" data-anchor-id="t-sne">T-SNE</h2>
<p>T-SNE is another dimensionality reduction method technique that transforms high dimensional data into lower 2D or 3D space. T-SNE first calculates the pairwise similarities between all data points in higher dimensional space.</p>
<p>This is done by utilizing a Gaussian distribution, calculating the probability that two points are similar. In reduced space, pairpise similarities are also computed, but using a Student-t distribution.</p>
<p>t-SNE’s goal is to minimzie the KL-Divergence(the measure of dissimimilarity between two distributions) between the high dimensional and low dimensional representations.</p>
<p>An important parameter of t-SNE is perplexity, influencing how local and global structures are represented in the dimensionality reduction. A low perplexity value puts more focus on retaining local structures, retaining local relationships, while a higher performance value puts more attention in the global structure, and may mean focusing on more distant value to preserve global structure.</p>
<p>Plotting t-SNE with varying levels of Perplexity values to understand the impact and importance of the Perplexity value.</p>
<p>A perplexity score of 5 is plotted first, and showcases tightly clustered datapoints, representing locally maintained structure.</p>
<p>A perplexity score of 30 is then plotted, showcasing more a spread out distribution of datapoints, but clusters are still visible. This represents a value that emphasizes both local and global structures, and normally the default when plotting.</p>
<p>Finally, a perplexity score of 50 is plotted, emphasizing global structure. This showcases a distribution similar to the perplexity score of 30, but with less visible structures.</p>
<div id="cell-11" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the standardized numerical data for t-SNE</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>numerical_data_for_tsne <span class="op">=</span> merged_standard_log_df[numerical_columns]</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply t-SNE with different perplexity values</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>perplexities <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">30</span>, <span class="dv">50</span>]</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>tsne_results <span class="op">=</span> {}</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> perplexity <span class="kw">in</span> perplexities:</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, perplexity<span class="op">=</span>perplexity)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    tsne_result <span class="op">=</span> tsne.fit_transform(numerical_data_for_tsne)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    tsne_results[perplexity] <span class="op">=</span> tsne_result</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot t-SNE results for different perplexity values</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, perplexity <span class="kw">in</span> <span class="bu">enumerate</span>(perplexities, <span class="dv">1</span>):</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, i)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    plt.scatter(tsne_results[perplexity][:, <span class="dv">0</span>], tsne_results[perplexity][:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f't-SNE with Perplexity </span><span class="sc">{</span>perplexity<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'t-SNE 1'</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'t-SNE 2'</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Plotting the t-SNE results with voting rate estimate, we see that regardless of perplexity score, each plot displays the pattern of grouping similar voting rates together.</p>
<p>With a perplexity of 5, small clusters are made up of similar voting rates, with some containing mixes.</p>
<p>A perplexity score of 30, despite having fewer distinct clusters, showcases gradient color pattern, splitting the data into regions of higher and lower voting rates.</p>
<p>A similar pattern is observed in a perplexity score of 50, with a much smoother and distinct gradient separating the difference in voting rates. A perplexity of 30 was selected for further analysis due to its balance of preserving both local and global structures.</p>
<div id="cell-13" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the standardized numerical data for t-SNE</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>numerical_data_for_tsne <span class="op">=</span> merged_standard_log_df[numerical_columns]</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>voting_rate <span class="op">=</span> merged_standard_log_df[<span class="st">'voting_rate_estimate'</span>]  <span class="co"># Your key feature</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply t-SNE with different perplexity values</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>perplexities <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">30</span>, <span class="dv">50</span>]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>tsne_results <span class="op">=</span> {}</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> perplexity <span class="kw">in</span> perplexities:</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, perplexity<span class="op">=</span>perplexity)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    tsne_result <span class="op">=</span> tsne.fit_transform(numerical_data_for_tsne)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    tsne_results[perplexity] <span class="op">=</span> tsne_result</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot t-SNE results with contextual overlay for different perplexity values</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, perplexity <span class="kw">in</span> <span class="bu">enumerate</span>(perplexities, <span class="dv">1</span>):</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, i)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    scatter <span class="op">=</span> plt.scatter(tsne_results[perplexity][:, <span class="dv">0</span>], </span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>                          tsne_results[perplexity][:, <span class="dv">1</span>], </span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>                          c<span class="op">=</span>voting_rate, cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f't-SNE with Perplexity </span><span class="sc">{</span>perplexity<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'t-SNE 1'</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'t-SNE 2'</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(scatter, label<span class="op">=</span><span class="st">'Voting Rate Estimate'</span>)  <span class="co"># Add a colorbar to show voting rate</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="effectiveness-of-pca-and-t-sne-in-preserving-data-structure" class="level1">
<h1>Effectiveness of PCA and t-SNE in preserving data structure</h1>
<section id="pca-1" class="level2">
<h2 class="anchored" data-anchor-id="pca-1">PCA</h2>
<p>PCA preserves global structures by maximizing variance utilizing the principal components. PCA may have issues with identifying local structures, however, if the PCA does not captures the variance within these clusters.</p>
</section>
<section id="t-sne-1" class="level2">
<h2 class="anchored" data-anchor-id="t-sne-1">t-SNE</h2>
<p>t-SNE is very good at maintaining local structures, making sure similar points stay together in the dimensionality reduction. t-SNE may have a harder time preserving global structures however, with farther distances in lower dimensional space plot not indicating true distances in higher dimensional space.</p>
<hr>
</section>
</section>
<section id="vizualizaion-with-pca-and-t-sne" class="level1">
<h1>Vizualizaion with PCA and t-SNE</h1>
<section id="pca-2" class="level2">
<h2 class="anchored" data-anchor-id="pca-2">PCA</h2>
<p>PCA is very good for visualizing data as it transforms data with many features into just 2, while capturing the majority of the variance. It provides a global broad view of the pattern of data, however has difficulty providing insight into local clusters and patterns for voting rates.</p>
</section>
<section id="t-sne-2" class="level2">
<h2 class="anchored" data-anchor-id="t-sne-2">t-SNE</h2>
<p>t-SNE also provides a clear visual representation of the data in reduced dimensional space, however emphasizes local structure more, and may have a harder time visualizing global structures. t-SNE’s axes, t-SNE 1 and t-SNE 2 also lack definition, making it difficult intepretnt compared to PCA.</p>
<hr>
</section>
</section>
<section id="comparing-pca-and-t-sne-tradeoffs" class="level1">
<h1>Comparing PCA and t-SNE tradeoffs</h1>
<section id="pca-3" class="level2">
<h2 class="anchored" data-anchor-id="pca-3">PCA</h2>
<p><strong>Strengths:</strong> - Reducing dimensionaly while preserving a large amount of variance and information. - Very good at preserving global structure, making it optimal for identifying trends and patterns. - Very good at handling data with linear relationships.</p>
<p><strong>Weaknesses:</strong> - Not very good at preserving local clusters and patterns if they have minimal contribution to variance. - Not good with handling data with non-linear relationships.</p>
<p><strong>Use case:</strong> Main goal is to reduce dimensions while preserving information, not as interesting clustering or finding local patterns.</p>
</section>
<section id="t-sne-3" class="level2">
<h2 class="anchored" data-anchor-id="t-sne-3">t-SNE</h2>
<p><strong>Strengths:</strong> - Optimal for preserving local structures, identifying local clusters and relationships. - Good for identifying hidden patterns utilzing non-linear relationships.</p>
<p><strong>Weaknesses:</strong> - Not as good at preserving global structures and identifying global trends and patterns. - Due to lack of defined axes, results are confusing to interpret.</p>
<p><strong>Use case:</strong> Main goal is for data exploration, finding local clusters and hidden patterns.</p>
<hr>
</section>
</section>
<section id="pca-vs-t-sne-results-analysis" class="level1">
<h1>PCA vs t-SNE Results Analysis</h1>
<p>The results and computations of PCA and t-SNE provides two different insights into our data.</p>
<section id="pca-results" class="level2">
<h2 class="anchored" data-anchor-id="pca-results">PCA Results</h2>
<p>The PCA results shows a uniform distribution of data points across our data space, not showing many clusters. Analysis tells us that PC1 is strongly correlated with voting rate estimate, linking it with factors such as median income and university education. The PCA does not showcase much patterns or clusters, reinforcing the idea that it is best used to identify global trends and patterns. In this case, it shows us that areas with higher income and education tend to have higher voter turnout.</p>
</section>
<section id="t-sne-results" class="level2">
<h2 class="anchored" data-anchor-id="t-sne-results">t-SNE Results</h2>
<p>The t-SNE result using perplexity of 30 shows a plot with distinct clusters, and after coloring with voting rate estimate, reveals a separation between high and low voting rates. This helps reveal sub-groups in our data, revealing patterns that are non-linear and not obvious. However, due to the axes of t-SNE not actually meaning anything, the clusters formed can only provide hints into relationships, not providing any actionable information.</p>
<hr>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Utilizing these two methods together provides insight into what drives the trends and patterns (through PCA) and where the trends and patterns are grouped together.</p>
</section>
</section>
<section id="clustering" class="level1">
<h1>Clustering</h1>
<p>The three types of clustering done on the data are K-means, DBSCAN, and Heirarchial. K-Means clustering is a very important and widely used technique to cluster data points utiliing the Euclidian Distance. Euclidean Distance, known as the straight line distance is the default distance metric used in machine learning.</p>
<hr>
<section id="k-means" class="level2">
<h2 class="anchored" data-anchor-id="k-means">K-means</h2>
<p>The K-Means algorithm utilizes the <code>n_clusters</code> parameter, a user-defined parameter indicating the number of centroids, or clusters one wishes the algorithm to use. The way K-means works involves randomly placing these centroids in the data space, and then utilizing Euclidean distance, assigns the closest data point to each centroid.</p>
<p>This creates the first set of clusters. In the next iteration, the mean of each cluster is set as the new centroid, and the new closest set of points are assigned to this new cluster. This algorithm continues until the clusters stabilize and converge. The goal of K-means clustering is to minimize the sum of square distances between centroid and it’s datapoints.</p>
<hr>
</section>
<section id="dbscan" class="level2">
<h2 class="anchored" data-anchor-id="dbscan">DBSCAN</h2>
<p>DBSCAN, short for “Density-Based Spatial Clustering of Applications with Noise,” is another clustering method, but unlike K-means, groups data points based on density rather than distance. DBSCAN is very good at identifying clusters of all shapes in comparison to K-means, and also does not need the user to specify the number of clusters, as it dynamically finds this based on data density.</p>
<p>DBSCAN takes in two important user-defined parameters, <code>EPS</code> (epsilon) and <code>Minpoints</code>. <code>EPS</code> dictates the maximum distance between two data points for them to be classified as part of the same cluster. <code>Minpoints</code> defines the minimum number of points needed for data points to be classified as a cluster. Similar to K-Means, the distance metric is Euclidean Distance.</p>
<p>The algorithm starts with an unvisited point, finds all points within the <code>EPS</code>, and if it reaches the threshold of <code>Minpoints</code>, becomes a cluster. The algorithm then expands, finding more points and clusters, repeating till no further points can be added.</p>
<hr>
</section>
<section id="hierarchical-clustering" class="level2">
<h2 class="anchored" data-anchor-id="hierarchical-clustering">Hierarchical Clustering</h2>
<p>Hierarchical Clustering is a type of clustering that involves a hierarchy of clusters. There are two types of Hierarchical clustering techniques: <strong>Agglomerative (Bottom-Up)</strong> and <strong>Divisive (Top-Down)</strong>.</p>
<ul>
<li><strong>Agglomerative Clustering</strong> starts off with all data points as its own cluster. The distances between these data points are calculated, and then grouped together based on the linkage criteria chosen.<br>
</li>
<li><strong>Divisive Clustering</strong> follows a similar pattern, but with a top-down approach. The data points start off as one big cluster, and continually get split based on linkage criteria until each data point is its own cluster.
<ul>
<li><strong>Linkage</strong> is the method used to measure distances between data points in hierarchical clustering.<br>
</li>
<li>Types of Linkage:
<ul>
<li><strong>Single Linkage</strong>: Closest distance between two points.</li>
<li><strong>Complete Linkage</strong>: Maximal distance between points.</li>
<li><strong>Average Linkage</strong>: Average distance between all points in a cluster.</li>
<li><strong>Ward Linkage</strong>: Measures the amount of variance within a cluster.</li>
</ul></li>
</ul></li>
</ul>
<p>We will be using <strong>Ward Linkage</strong> for its minimization of variation within clusters and its practicality. After the first initial cluster is set, the distances are once again computed between clusters, and are continually merged until there is only 1 cluster left.</p>
<p>Hierarchical clustering creates a <strong>dendrogram</strong>, a tree-like structure, providing information on how clusters merge and split.</p>
<hr>
</section>
<section id="hyperparameter-optimization" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameter-optimization">Hyperparameter Optimization</h2>
<p>To maximize the use of these algorithms, we utilize a hyperparameter called <strong>Silhouette Score</strong>. Silhouette score is the metric used to validate the quality of a cluster, comparing how well each data point is with its own cluster and other clusters.</p>
<p><span class="math display">\[
S(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
\]</span></p>
<ul>
<li><strong>Formula Explanation</strong>:<br>
With <code>A(i)</code> being the average distance between the point and other points in its own cluster, and <code>B(i)</code> being the average distance between the point and all other points in the next closest cluster. The score is between -1 and 1, with a higher score indicating a more compact, distinct cluster.</li>
</ul>
<hr>
<section id="using-silhouette-score-for-optimization" class="level3">
<h3 class="anchored" data-anchor-id="using-silhouette-score-for-optimization">Using Silhouette Score for Optimization</h3>
<ul>
<li><p><strong>K-Means</strong>:<br>
Use the silhouette score to calculate the optimal number of clusters by plotting the score against <code>n_clusters</code>. The optimal number of clusters corresponds to the highest silhouette score.</p></li>
<li><p><strong>DBSCAN</strong>:<br>
Use the silhouette score to calculate the optimal <code>EPS</code> parameter. This is done by plotting the silhouette score against <code>EPS</code>, and the optimal clusters will correspond to the maximum silhouette score.</p></li>
<li><p><strong>Hierarchical Clustering</strong>:<br>
The silhouette score is evaluated to find the optimal place to “cut” the dendrogram. The number of clusters at which the silhouette score is maximized is used as the cut-off point for the dendrogram.</p></li>
</ul>
</section>
</section>
</section>
<section id="k-means-1" class="level1">
<h1>K-Means</h1>
<div id="cell-16" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans, Birch, AgglomerativeClustering, DBSCAN, SpectralClustering</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.cluster</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># THIS WILL ITERATE OVER ONE HYPER-PARAMETER (GRID SEARCH)</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># AND RETURN THE CLUSTER RESULT THAT OPTIMIZES THE SILHOUETTE SCORE</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.cluster</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co"># THIS WILL ITERATE OVER ONE HYPER-PARAMETER (GRID SEARCH) </span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># AND RETURN THE CLUSTER RESULT THAT OPTIMIZES THE SILHOUETTE SCORE</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> maximize_silhouette1(X,algo<span class="op">=</span><span class="st">"birch"</span>,nmax<span class="op">=</span><span class="dv">20</span>,i_plot<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PARAM</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    i_print<span class="op">=</span><span class="va">False</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#FORCE CONTIGUOUS</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>np.ascontiguousarray(X) </span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># LOOP OVER HYPER-PARAM</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>[]<span class="op">;</span> sil_scores<span class="op">=</span>[]</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    sil_max<span class="op">=-</span><span class="dv">10</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> param <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>,nmax<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(algo<span class="op">==</span><span class="st">"birch"</span>):</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> sklearn.cluster.Birch(n_clusters<span class="op">=</span>param).fit(X)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>model.predict(X)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(algo<span class="op">==</span><span class="st">"ag"</span>):</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> sklearn.cluster.AgglomerativeClustering(n_clusters<span class="op">=</span>param).fit(X)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>model.labels_</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(algo<span class="op">==</span><span class="st">"dbscan"</span>):</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>            param<span class="op">=</span><span class="fl">0.5</span><span class="op">*</span>(param<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> sklearn.cluster.DBSCAN(eps<span class="op">=</span>param).fit(X)</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>model.labels_</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(algo<span class="op">==</span><span class="st">"kmeans"</span>):</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> sklearn.cluster.KMeans(n_clusters<span class="op">=</span>param).fit(X)</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>model.predict(X)</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>            sil_scores.append(sklearn.metrics.silhouette_score(X,labels))</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>            params.append(param)</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span>:</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span> </span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(i_print): <span class="bu">print</span>(param,sil_scores[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(sil_scores[<span class="op">-</span><span class="dv">1</span>]<span class="op">&gt;</span>sil_max):</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>             opt_param<span class="op">=</span>param</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>             sil_max<span class="op">=</span>sil_scores[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a>             opt_labels<span class="op">=</span>labels</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a>             </span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>             </span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"OPTIMAL PARAMETER ="</span>,opt_param)</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"MAXIMUM SILHOUETTE SCORE ="</span>, sil_max)</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(i_plot):</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>        ax.plot(params, sil_scores, <span class="st">"-o"</span>)  </span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a>        ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'Hyper-parameter'</span>, ylabel<span class="op">=</span><span class="st">'Silhouette'</span>)</span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> opt_labels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-17" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>opt_labels<span class="op">=</span>maximize_silhouette1(numerical_data,algo<span class="op">=</span><span class="st">"kmeans"</span>,nmax<span class="op">=</span><span class="dv">15</span>, i_plot<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>OPTIMAL PARAMETER = 2
MAXIMUM SILHOUETTE SCORE = 0.18366963443756543</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-18" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply KMeans</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)  </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>kmeans_labels <span class="op">=</span> kmeans.fit_predict(numerical_data)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>merged_standard_log_df[<span class="st">'Kmeans_Label'</span>] <span class="op">=</span> kmeans_labels</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>plt.scatter(numerical_data.iloc[:, <span class="dv">0</span>], numerical_data.iloc[:, <span class="dv">1</span>], c<span class="op">=</span>kmeans_labels, cmap<span class="op">=</span><span class="st">'viridis'</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"KMeans Clustering"</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Using the optimal parameter of 2, the k-means clustering is plotted below. The data is separated into two separate distinct clusters. There is a lot of overlap towards the middle, which may indicate kmeans is having trouble cleanly separating the two groups.</p>
<div id="cell-20" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the y-values for your subplots (now x-values since axes are flipped)</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>x_values <span class="op">=</span> [</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'White'</span>, <span class="st">'Log_African_American'</span>, <span class="st">'Log_Asian'</span>, <span class="st">'Below_Poverty_Level'</span>,</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Bachelors_Degree_or_Higher'</span>, <span class="st">'Median_Age'</span>, <span class="st">'Households_with_Internet'</span>, <span class="st">'High_School_Graduate'</span>, <span class="st">'Veterans'</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the grid dimensions</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>ncols <span class="op">=</span> <span class="dv">3</span>  <span class="co"># Number of columns in the grid</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>nrows <span class="op">=</span> (<span class="bu">len</span>(x_values) <span class="op">+</span> ncols <span class="op">-</span> <span class="dv">1</span>) <span class="op">//</span> ncols  <span class="co"># Calculate rows based on the number of columns</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subplots</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span>nrows, ncols<span class="op">=</span>ncols, figsize<span class="op">=</span>(<span class="dv">15</span>, nrows <span class="op">*</span> <span class="dv">5</span>))</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten()  <span class="co"># Flatten axes for easy iteration</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate scatter plots for each x-value</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax, x <span class="kw">in</span> <span class="bu">zip</span>(axes, x_values):</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    sns.scatterplot(</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>x,</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">'voting_rate_estimate'</span>,</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        hue<span class="op">=</span><span class="st">'Kmeans_Label'</span>,</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        data<span class="op">=</span>merged_standard_log_df,</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        palette<span class="op">=</span><span class="st">'Set1'</span>,</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        ax<span class="op">=</span>ax</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss"> vs voting_rate_estimate'</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(x)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'voting_rate_estimate'</span>)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn off any unused subplots</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes[<span class="bu">len</span>(x_values):]:</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust layout for better spacing</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>When plotting KMeans clusters with specific features and voting rates, distinct patterns emerged:</p>
<ul>
<li><strong>Cluster 0</strong> is associated with <strong>higher voting rates</strong> and higher values for features such as:
<ul>
<li><strong>White population</strong><br>
</li>
<li><strong>Asian population</strong><br>
</li>
<li><strong>Median Age</strong><br>
</li>
<li><strong>Bachelor’s Degree or Higher</strong><br>
</li>
<li><strong>Households with Internet</strong></li>
</ul></li>
<li><strong>Cluster 1</strong> is associated with <strong>lower voting rates</strong> and higher values for:
<ul>
<li><strong>African American population</strong><br>
</li>
<li><strong>Below Poverty Level</strong></li>
</ul></li>
<li><strong>No clear correlation</strong> was observed for <strong>Veterans</strong>, maybe slightly correlated with higher voting rates</li>
</ul>
<p>This suggests that socioeconomic and demographic factors like education, internet access, and income have a strong relationship with voting rates.</p>
</section>
<section id="dbscan-1" class="level1">
<h1>DBSCAN</h1>
<div id="cell-22" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>opt_labels<span class="op">=</span>maximize_silhouette1(numerical_data,algo<span class="op">=</span><span class="st">"dbscan"</span>,nmax<span class="op">=</span><span class="dv">15</span>, i_plot<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>OPTIMAL PARAMETER = 5.0
MAXIMUM SILHOUETTE SCORE = 0.5884911578847557</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Using the optimal parameter of 5, we saw that 1 cluster dominated the features space , with 1 other data point being labeled as noise.</p>
<p>With visual inspection, it was found that EPS scores around 2-3 provided more distinct clusters. With an EPS of 5, this is a large EPS, and may lead to the data being clumped into one large cluster, which is what appears to be. I chose an EPS of 2.5 for further analysis as it provided a good distribution between two clusters.</p>
<section id="dbscan-with-varied-eps" class="level2">
<h2 class="anchored" data-anchor-id="dbscan-with-varied-eps">DBSCAN With Varied EPS</h2>
<div id="cell-24" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the eps values to test</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>eps_values <span class="op">=</span> [<span class="fl">1.5</span>, <span class="dv">2</span>, <span class="fl">2.5</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>]</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subplots</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten()</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply DBSCAN with different eps values and plot the results</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, eps <span class="kw">in</span> <span class="bu">enumerate</span>(eps_values):</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span>eps, min_samples<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    dbscan_labels <span class="op">=</span> dbscan.fit_predict(numerical_data)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    axes[i].scatter(</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        numerical_data.iloc[:, <span class="dv">0</span>],</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        numerical_data.iloc[:, <span class="dv">1</span>],</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        c<span class="op">=</span>dbscan_labels,</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        cmap<span class="op">=</span><span class="st">'viridis'</span>,</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        s<span class="op">=</span><span class="dv">10</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f"DBSCAN with eps=</span><span class="sc">{</span>eps<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    axes[i].grid()</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust layout</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>When plotting the DBSCAN clusters with voting rate, it was difficult to make out any clear patterns or trends. Low Voting rate estimates were in the same clusters a high voting rates, and didn’t provide any new insights or information regarding the data</p>
<p>## DBSCAN Plotted with Voting Rate</p>
<div id="cell-26" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">2.5</span>, min_samples<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>dbscan_labels <span class="op">=</span> dbscan.fit_predict(numerical_data)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Overlay voting rate estimate on DBSCAN clusters</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    numerical_data.iloc[:, <span class="dv">0</span>],</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    numerical_data.iloc[:, <span class="dv">1</span>],</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    c<span class="op">=</span>merged_standard_log_df[<span class="st">'voting_rate_estimate'</span>],  <span class="co"># Overlay voting rate estimate</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">'viridis'</span>,  <span class="co"># Use a diverging colormap for better visibility</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span><span class="dv">10</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, label<span class="op">=</span><span class="st">'Voting Rate Estimate'</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"DBSCAN Clustering (eps=2.5) with Voting Rate Overlay"</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="dbscan-plotted-with-voting-rate-and-key-features" class="level2">
<h2 class="anchored" data-anchor-id="dbscan-plotted-with-voting-rate-and-key-features">DBSCAN Plotted with Voting Rate and Key Features</h2>
<div id="cell-28" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming we have numerical_data and merged_standard_log_df loaded with the necessary data</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Features to plot against voting_rate_estimate</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">'White'</span>, <span class="st">'Log_African_American'</span>, <span class="st">'Log_Asian'</span>, <span class="st">'Below_Poverty_Level'</span>,</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Bachelors_Degree_or_Higher'</span>, <span class="st">'Median_Age'</span>, <span class="st">'Households_with_Internet'</span>, <span class="st">'High_School_Graduate'</span>, <span class="st">'Veterans'</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply DBSCAN with eps=2.5 and assign cluster labels</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">2.5</span>, min_samples<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>dbscan_labels <span class="op">=</span> dbscan.fit_predict(numerical_data)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the DBSCAN cluster labels to the DataFrame</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>merged_standard_log_df[<span class="st">'DBSCAN_Cluster'</span>] <span class="op">=</span> dbscan_labels</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of rows and columns for subplots</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>ncols <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>nrows <span class="op">=</span> (<span class="bu">len</span>(features) <span class="op">+</span> ncols <span class="op">-</span> <span class="dv">1</span>) <span class="op">//</span> ncols</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subplots</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span>nrows, ncols<span class="op">=</span>ncols, figsize<span class="op">=</span>(<span class="dv">15</span>, nrows <span class="op">*</span> <span class="dv">5</span>))</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten()  <span class="co"># Flatten axes for easier iteration</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate scatter plots for each feature against voting_rate_estimate</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax, feature <span class="kw">in</span> <span class="bu">zip</span>(axes, features):</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    sns.scatterplot(</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>feature,</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">'voting_rate_estimate'</span>,  <span class="co"># Voting rate on the y-axis</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        hue<span class="op">=</span><span class="st">'DBSCAN_Cluster'</span>,  <span class="co"># Color by DBSCAN cluster labels</span></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        data<span class="op">=</span>merged_standard_log_df,</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>        palette<span class="op">=</span><span class="st">'Set1'</span>,</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>        ax<span class="op">=</span>ax</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss"> vs Voting Rate"</span>)</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(feature)</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"Voting Rate Estimate"</span>)</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn off any unused subplots</span></span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes[<span class="bu">len</span>(features):]:</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust layout for better spacing</span></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>When plotting important features with voting rate, and labeling with clusters, it similarly does not show any actionable information, with a mixed distribution of clusters spread through distribution. DBSCAN was not the best suited method for this type of data.</p>
<p>DBSCAN groups data together based on density- if the density of points are all uniformly distributed, it is very difficult for DBSCAN to make any distinctions between groups. This may have occurred with Voting Rate, with this feature having more of a gradual transition across the data, as opposed to distinct clusters that DBSCAN assumes.</p>
</section>
</section>
<section id="hierarchical-clustering-1" class="level1">
<h1>Hierarchical Clustering</h1>
<div id="cell-30" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>opt_labels_agglomerative <span class="op">=</span> maximize_silhouette1(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    numerical_data, algo<span class="op">=</span><span class="st">"ag"</span>, nmax<span class="op">=</span><span class="dv">10</span>, i_plot<span class="op">=</span><span class="va">True</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>merged_standard_log_df[<span class="st">'Hierarchical_Cluster'</span>] <span class="op">=</span> opt_labels_agglomerative</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>OPTIMAL PARAMETER = 2
MAXIMUM SILHOUETTE SCORE = 0.15594044121346587</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-16-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-31" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> dendrogram, linkage</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use District_Name from merged_standard_log_df as labels</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> merged_standard_log_df[<span class="st">'District_Name'</span>]  <span class="co"># Pull labels from the correct DataFrame</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># TOO BIG</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the linkage matrix using numerical columns only</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> linkage(numerical_data, method<span class="op">=</span><span class="st">'ward'</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the dendrogram</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">6</span>))</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>dendrogram(</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    Z,</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    no_labels<span class="op">=</span><span class="va">True</span>,  <span class="co"># Remove labels</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Dendrogram"</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Clustered Data Points"</span>)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Distance"</span>)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Analyzing Hierarchical Clustering, our hyperparameter testing told us that cutting the dendrogram at k = 2 would give us the highest silhouette score, and most optimal clustering.</p>
<p>After grouping the data points into the cluster it belongs to and plotting against ‘voting rate estimate’, we are able to see that cluster 1 has a significantly higher voting rate average than cluster 2. ## Voting Rate by Hierarchical Clusters</p>
<div id="cell-33" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Box plot for voting_rate_estimate by cluster</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>sns.boxplot(x<span class="op">=</span><span class="st">'Hierarchical_Cluster'</span>, y<span class="op">=</span><span class="st">'voting_rate_estimate'</span>, data<span class="op">=</span>merged_standard_log_df)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Voting Rate by Hierarchical Clusters"</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Cluster"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Voting Rate Estimate"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-34" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot with hierarchical cluster coloring</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot for multiple pairs of features with hierarchical cluster coloring</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Features to plot</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>  <span class="st">'White'</span>, <span class="st">'Log_African_American'</span>, <span class="st">'Log_Asian'</span>, <span class="st">'Below_Poverty_Level'</span>,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Bachelors_Degree_or_Higher'</span>, <span class="st">'Median_Age'</span>, <span class="st">'Households_with_Internet'</span>, <span class="st">'High_School_Graduate'</span>, <span class="st">'Veterans'</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of rows and columns for subplots</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>ncols <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>nrows <span class="op">=</span> (<span class="bu">len</span>(features) <span class="op">+</span> ncols <span class="op">-</span> <span class="dv">1</span>) <span class="op">//</span> ncols</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subplots</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span>nrows, ncols<span class="op">=</span>ncols, figsize<span class="op">=</span>(<span class="dv">15</span>, nrows <span class="op">*</span> <span class="dv">5</span>))</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten()  <span class="co"># Flatten axes for easier iteration</span></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate scatter plots for each feature against voting_rate_estimate</span></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax, feature <span class="kw">in</span> <span class="bu">zip</span>(axes, features):</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    sns.scatterplot(</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>feature,</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">'voting_rate_estimate'</span>,  <span class="co"># Voting rate on the y-axis</span></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>        hue<span class="op">=</span><span class="st">'Hierarchical_Cluster'</span>,  <span class="co"># Color by cluster labels</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        data<span class="op">=</span>merged_standard_log_df,</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>        palette<span class="op">=</span><span class="st">'Set1'</span>,</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        ax<span class="op">=</span>ax</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss"> vs Voting Rate"</span>)</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(feature)</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"Voting Rate Estimate"</span>)</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn off any unused subplots</span></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes[<span class="bu">len</span>(features):]:</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust layout for better spacing</span></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>When plotting important features with Voting Rate and assigning cluster labels, we see a similar pattern emerge as K-means, but not as distinct. White, African American, and Median Age had no clear correlation, however Bachelors Degree or Higher and Asian had higher coting rate for the higher values, and Below Poverty Level had lower rates of voting for higher values of poverty level. The features with no clear correlation may be due to the fact they contribute smaller variance to the clustering method, or truly have no correlation to voting rates.</p>
</section>
<section id="comparing-the-results" class="level1">
<h1><strong>Comparing the Results</strong></h1>
<hr>
<section id="k-means-clustering" class="level2">
<h2 class="anchored" data-anchor-id="k-means-clustering"><strong>K-Means Clustering</strong></h2>
<ul>
<li><strong>Clusters</strong>: Produced <strong>2 clear clusters</strong>:
<ul>
<li><strong>Cluster 0</strong>: Aligned with <strong>higher voting rates</strong>.<br>
</li>
<li><strong>Cluster 1</strong>: Aligned with <strong>lower voting rates</strong>.<br>
</li>
</ul></li>
<li><strong>Key Insights</strong>:
<ul>
<li>Higher voting rates are associated with:
<ul>
<li><strong>White</strong> and <strong>Asian</strong> populations<br>
</li>
<li><strong>Median Age</strong><br>
</li>
<li><strong>Bachelor’s Degree</strong> attainment<br>
</li>
</ul></li>
<li>Lower voting rates are associated with:
<ul>
<li><strong>African American</strong> population<br>
</li>
<li><strong>Below Poverty Level</strong><br>
</li>
</ul></li>
</ul></li>
<li><strong>Summary</strong>: K-Means effectively captured strong correlations between clusters and features, proving to be an <strong>optimal choice</strong> for uncovering relationships in the data.</li>
</ul>
<hr>
</section>
<section id="dbscan-clustering" class="level2">
<h2 class="anchored" data-anchor-id="dbscan-clustering"><strong>DBSCAN Clustering</strong></h2>
<ul>
<li><strong>Optimal EPS</strong>:
<ul>
<li>At <strong>EPS = 5</strong>: 1 large cluster, with <strong>1 data point labeled as noise</strong>.<br>
</li>
<li>At <strong>EPS = 2.5</strong>: Clear group separation, but <strong>no actionable patterns or insights</strong> emerged.<br>
</li>
</ul></li>
<li><strong>Summary</strong>: DBSCAN did not produce meaningful or valuable information for this dataset.</li>
</ul>
<hr>
</section>
<section id="hierarchical-clustering-2" class="level2">
<h2 class="anchored" data-anchor-id="hierarchical-clustering-2"><strong>Hierarchical Clustering</strong></h2>
<ul>
<li><strong>Clusters</strong>: Produced <strong>2 clusters</strong>:
<ul>
<li><strong>Cluster 1</strong>: Higher voting rates.<br>
</li>
<li><strong>Cluster 2</strong>: Lower voting rates.<br>
</li>
</ul></li>
<li><strong>Key Observations</strong>:
<ul>
<li>Similar to K-Means, there was a clear cluster separation.<br>
</li>
<li>Results were <strong>less distinct</strong>, with mixed cluster label distributions across many features.<br>
</li>
</ul></li>
<li><strong>Summary</strong>: While hierarchical clustering highlighted general patterns, it was <strong>less effective</strong> than K-Means.</li>
</ul>
<hr>
</section>
<section id="best-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="best-algorithm"><strong>Best Algorithm</strong></h2>
<ul>
<li>The <strong>best clustering algorithm</strong> for this dataset was <strong>K-Means</strong>, followed by hierarchical clustering.<br>
</li>
<li><strong>Why K-Means?</strong>
<ul>
<li>Produced the <strong>most distinct and clear insights</strong> into relationships between features and voting rates.<br>
</li>
<li>Likely due to the <strong>linear relationships</strong> in the data, which K-Means efficiently uncovers.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="real-world-impact" class="level2">
<h2 class="anchored" data-anchor-id="real-world-impact"><strong>Real World Impact</strong></h2>
<p>Utilizing the findings from <strong>K-Means</strong>, we uncovered hidden patterns between voting rates and socioeconomic groups:</p>
<ol type="1">
<li><strong>Lower Education → Lower Voting Rates</strong>
<ul>
<li><strong>Actionable Insight</strong>: Implement targeted <strong>voter education programs</strong> in communities with lower education levels, emphasizing the importance of civic participation.</li>
</ul></li>
<li><strong>Higher Poverty Levels → Lower Voting Rates</strong>
<ul>
<li><strong>Actionable Insight</strong>: Address socioeconomic barriers:
<ul>
<li>Implement <strong>paid time off for voting</strong> for individuals in poverty, ensuring they have the flexibility to vote.<br>
</li>
<li>Develop <strong>childcare support</strong> and <strong>transportation programs</strong> for families and individuals in need on election day.</li>
</ul></li>
</ul></li>
</ol>
<p>By leveraging these insights, policymakers and stakeholders can design targeted initiatives to <strong>increase voter participation</strong> and foster a more inclusive democracy.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>